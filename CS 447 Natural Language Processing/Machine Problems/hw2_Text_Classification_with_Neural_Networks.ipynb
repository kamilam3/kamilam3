{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSy-sfxOsclS"
      },
      "source": [
        "# CS 447 Homework 2 $-$ Text Classification with Neural Networks\n",
        "In this homework, you will build machine learning models to detect the sentiment of movie reviews using the IMDb movie reviews dataset. Specifically, you will implement classifiers based on Convolutional Neural Networks (CNN's) and Recurrent Neural Networks (RNN's).\n",
        "\n",
        "In addition to the Pytorch tutorial we have provided on Coursera, we highly recommend that you take a look at the PyTorch tutorials before starting this assignment:\n",
        "<ul>\n",
        "<li><a href=\"https://pytorch.org/tutorials/beginner/pytorch_with_examples.html\">https://pytorch.org/tutorials/beginner/pytorch_with_examples.html</a>\n",
        "<li><a href=\"https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\">https://pytorch.org/tutorials/beginner/data_loading_tutorial.html</a>\n",
        "<li><a href=\"https://github.com/yunjey/pytorch-tutorial\">https://github.com/yunjey/pytorch-tutorial</a>\n",
        "</ul>\n",
        "\n",
        "<font color='green'>While you work, we suggest that you keep your hardware accelerator set to \"CPU\" (the default for Colab). However, when you have finished debugging and are ready to train your models, you should select \"GPU\" as your runtime type. This will speed up the training of your models. You can find this by going to <TT>Runtime > Change Runtime Type</TT> and select \"GPU\" from the dropdown menu.</font>\n",
        "\n",
        "As usual, you should not import any other libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EyCOvTRQ1nb-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2cd107e-6d07-4db0-9603-3e1b56312f37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "### DO NOT EDIT ###\n",
        "\n",
        "import torch\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "if __name__=='__main__':\n",
        "    print('Using device:', DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHbJ1-aDsWCG"
      },
      "source": [
        "# Step 1: Download the Data\n",
        "First we will download the dataset using [torchtext](https://torchtext.readthedocs.io/en/latest/index.html), which is a package that supports NLP for PyTorch.\n",
        "\n",
        "Unfortunately, you have to install the <TT>torchdata</TT> package on the Colab machine in order to access the data. To do this, run the cell below (you may need to click the \"Restart Runtime\" button when it finishes). You will have to do this every time you return to work on the homework.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rT4n4QzHAYe_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f84807f6-9608-4cb2-f82a-2975fbd9ed2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchdata in /usr/local/lib/python3.10/dist-packages (0.6.1)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.31.0)\n",
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchdata) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchdata) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchdata) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchdata) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchdata) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchdata) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchdata) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchdata) (16.0.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->torchdata) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->torchdata) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchdata\n",
        "!pip install portalocker>=2.0.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMVBA0ijAUgt"
      },
      "source": [
        "The following cell will get you `train_data` and `test_data`. It also does some basic tokenization.\n",
        "\n",
        "*   To access the list of textual tokens for the *i*th example, use `train_data[i][1]`\n",
        "*   To access the label for the *i*th example, use `train_data[i][0]`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dfX3bNby8FYL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0992d42-1deb-4d1d-a006-cb9953e0fc0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num. Train Examples: 20000\n",
            "Num. Test Examples: 5000\n",
            "\n",
            "SAMPLE DATA:\n",
            "Sample text: ['This', 'game', 'was', 'made', 'by', 'Sega', '.', 'Being', 'made', 'by', 'Sega', 'I', \"didn't\", 'expect', 'much', ',', 'but', 'I', 'also', \"didn't\", 'expect', 'this', 'junk', 'either', '.', 'For', 'starters', 'the', 'camera', 'angles', 'work', 'against', 'you', 'in', 'this', 'game', '.', 'The', 'motorcycle', 'is', 'your', 'means', 'of', 'getting', 'around', '.', 'The', 'motorcycle', 'is', 'the', 'worst', 'part', 'in', 'the', 'game', '.', 'Whenever', 'you', 'run', 'in', 'to', 'something', 'you', 'just', 'stick', 'there', 'and', 'you', \"don't\", 'move', '.', 'You', 'never', 'fall', 'off', 'the', 'bike', 'or', 'wreck', 'for', 'that', 'matter', '.', 'The', 'main', 'character', 'hardly', 'talks', 'even', 'though', \"he's\", 'got', 'a', 'voice', 'that', 'suits', 'him', '.', 'The', 'graphics', 'are', 'horrible', '.', 'You', 'ride', 'through', 'trees', 'on', 'your', 'bike', '.', 'The', 'camera', 'makes', 'fighting', 'the', 'enemy', 'impossible', '.', 'This', 'game', \"wouldn't\", 'even', 'be', 'worth', 'renting', '.']\n",
            "Sample label: 1 \n",
            "\n",
            "Sample text: ['There', 'was', 'such', 'a', 'hype', 'about', 'a', 'game', 'show', 'with', 'Bill', 'Shatner...and', 'especially', 'right', 'in', 'the', 'wake', 'of', 'Deal', 'or', 'No', 'Deal', 'and', '1', 'vs', '100', '.', 'So', ',', 'of', 'course', 'everyone', 'had', 'to', 'tune', 'in', 'to', 'see', 'what', 'all', 'the', 'fuss', 'was', 'about', 'on', 'the', 'new', 'game', 'show', '.', 'What', 'a', 'disappointment', '!', 'As', 'Ben', 'Stein', 'so', 'stoically', 'and', 'nasally', 'says', ',', '\"', 'wooww\".<br', '/><br', '/>The', 'only', 'thing', 'likable', 'about', 'this', 'show', 'was', 'the', 'fact', 'that', 'you', 'knew', 'it', 'would', 'eventually', 'be', 'over', '.', 'Sitting', 'through', 'a', 'full', 'hour', 'of', 'it', 'was', 'like', 'going', 'to', 'the', 'dentist...you', 'find', 'yourself', 'looking', 'at', 'the', 'clock', 'in', 'what', 'you', 'think', 'are', '10', 'minute', 'intervals', ',', 'only', 'to', 'find', 'out', 'that', 'only', 'a', 'minute', 'has', 'passed', '(', 'but', 'seemed', 'like', 'an', 'eternity', ')', 'since', 'you', 'last', 'glanced', 'at', 'the', 'clock', '.', 'So', ',', 'why', \"didn't\", 'I', 'just', 'switch', 'the', 'channel', '?', 'Well', ',', 'probably', 'for', 'the', 'same', 'reason', 'most', 'other', 'people', \"didn't...out\", 'of', 'sheer', 'optimism', '.', 'I', 'mean', ',', 'no', 'one', 'really', '*wants*', 'to', 'think', 'that', 'a', 'show', 'with', 'Bill', 'Shatner', 'could', 'actually', 'be', 'SO', 'BAD.<br', '/><br', '/>Personally', ',', 'from', 'the', 'first', '15', 'minutes', ',', 'I', 'never', 'thought', 'this', 'was', 'the', 'kind', 'of', 'vehicle', 'that', 'would', 'showcase', 'the', 'talents', 'of', 'William', 'Shatner', '.', 'My', 'chief', 'complaint', 'was', 'that', 'the', 'set', 'was', 'so', 'dark', '.', 'Watching', 'it', 'left', 'me', 'feeling', 'depressed', '.', 'You', 'kept', 'on', 'wanting', 'to', 'get', 'ahold', 'of', 'a', 'little', 'excitement', ',', 'but', 'there', 'was', 'just', 'none', 'to', 'be', 'had', '.', 'There', 'was', 'not', 'even', 'enough', 'light', 'on', 'the', 'set', 'to', 'get', 'a', 'feel', 'of', 'energy', 'from', 'the', 'audience', '(', 'who', 'you', \"couldn't\", 'even', 'see).<br', '/><br', '/>Dear', 'Network', ':', 'People', 'do', 'not', 'watch', 'game', 'shows', 'to', 'cure', 'their', 'insomnia...they', 'watch', 'game', 'shows', 'to', 'be', 'excited', 'and', 'have', 'a', 'good', 'time', '.', 'Please', 'do', 'us', 'all', 'a', 'favor', 'and', 'lose', 'this', 'in', 'the', 'vault', '.']\n",
            "Sample label: 1 \n",
            "\n",
            "Sample text: ['The', 'summer', 'has', 'been', 'so', 'full', 'of', 'Blockbusters', 'and', 'comebacks', 'of', 'films', ',', 'and', 'not', 'to', 'mention', 'some', 'of', 'the', 'disappointments', 'of', 'those', 'comebacks', ',', 'that', 'I', 'was', 'woe', 'to', 'find', 'a', 'film', 'I', 'could', 'just', 'sit', 'down', 'and', 'enjoy', '.', '<br', '/><br', '/>In', 'case', 'you', \"don't\", 'want', 'to', 'read', 'further', 'down', 'the', 'page', '(', 'there', \"aren't\", 'any', 'spoilers)', ',', \"I'll\", 'sum', 'it', 'up', 'here', ':', \"It's\", 'more', 'mature', 'than', 'Ella', 'Enchanted', '(', 'there', 'are', 'some', 'questionably', 'violent', 'parts', ',', 'plenty', 'of', 'death', ',', 'and', 'a', 'handful', 'of', 'scenes', 'with', 'a', 'little', 'blood', ',', 'not', 'for', 'small', 'children)', ',', 'but', \"doesn't\", 'try', 'to', 'be', 'overly', 'corny', 'or', 'overstep', 'its', 'bounds', '.', 'Think', 'of', 'it', 'as', 'a', 'bit', 'more', 'serious', ',', 'bit', 'more', 'magical', 'Princess', 'Bride', ',', 'and', \"you'll\", 'be', 'close', '.', '<br', '/><br', '/>-------------------------------------------------------------<br', '/><br', '/>I', 'am', ',', 'perhaps', ',', 'not', 'as', 'prodigious', 'a', 'movie', 'goer', 'as', 'others..', '.', 'Maybe', 'once', 'or', 'twice', 'a', 'month', ',', 'if', 'I', 'feel', 'active', '.', \"I'm\", 'also', 'a', 'huge', 'Sci-Fi/Fantasy', 'fan', '.', 'I', 'get', 'bored', 'of', 'remade', 'repetitive', 'story', 'lines', 'and', 'films', 'with', 'more', 'flash', 'than', 'filling', 'faster', 'than', 'you', 'can', 'count', 'to', '10', ',', 'and', 'this', 'film', 'is', 'the', 'diamond', 'in', 'the', 'rough.<br', '/><br', '/>By', 'the', 'end', 'here', '(', 'August)', ',', 'I', 'was', 'tired', 'enough', 'of', 'fractured', 'expectations', 'from', 'the', 'big', 'hits', 'that', 'I', 'averted', 'seeing', 'Bourne', 'Ultimatum', 'in', 'favor', 'of', 'Stardust', '.', 'Having', 'had', 'my', 'hopes', 'thoroughly', 'muddied', 'by', 'Transformers', 'for', 'my', 'Fiction', 'addiction', ',', 'the', 'previews', 'of', 'Stardust', 'seemed', 'appealing', ',', 'but', 'I', 'was', 'certainly', 'wary.<br', '/><br', '/>As', 'many', 'others', 'here', ',', 'I', 'was', 'utterly', 'surprised', '.', 'I', 'had', 'gone', 'in', 'thinking', 'to', 'see', 'another', 'generic', 'fantasy', 'movie', 'clichéd', 'from', 'here', 'to', 'breakfast', '.', \"Don't\", 'be', 'fooled', ',', 'it', 'is', 'most', 'definitely', 'a', 'fairy-tale', ',', 'and', 'it', 'does', 'indeed', 'have', 'witches', ',', 'magic', ',', 'and', 'utterly', 'requires', 'suspension', 'of', 'disbelief..', '.', 'But', 'the', 'most', 'refreshing', 'thing', 'I', 'found', ',', 'is', 'that', \"it's\", 'NOT', 'based', 'on', 'anything', \"I've\", 'seen', 'or', 'read', 'in', 'the', 'past', '15', 'years', ',', 'and', \"it's\", 'actually', 'a', 'really', 'good', 'movie.<br', '/><br', '/>((Unlike', '90%', 'of', 'the', 'other', 'movies', 'which', 'seem', 'to', 'persistently', 're-appear', 'like', 'thorns', 'in', 'a', 'side', ',', 'perhaps', 'a', 'sign', 'that', 'Hollywood', 'is', 'running', 'out', 'of', 'ideas', '?', 'I', 'could', 'read', 'a', 'book', 'this', 'year', ',', 'and', 'in', 'two', 'years', 'the', 'movie', 'would', 'be', 'out', 'as', 'another', '\"', 'Epic', 'fantasy', 'tale', ',', 'the', 'likes', 'of', 'LotR', 'and', 'the', 'rest', '\"', 'so', 'says', 'the', 'NYT', 'and', 'such', 'and', 'such', 'no', 'doubt.))<br', '/><br', '/>Stardust', \"didn't\", 'have', 'me', 'bolted', 'to', 'my', 'seat', 'because', 'of', 'jam-packed', 'action', 'at', 'every', 'turn', ',', 'nor', 'was', 'I', 'sweating', 'bullets', 'because', 'of', 'plot-hook', 'after', 'plot-hook', 'threatening', 'to', 'tear', 'the', 'dramatic', 'tension', 'apart', 'and', 'echo', 'throughout', 'the', 'theater', 'in', 'a', 'loud', 'boom', '.', 'It', \"didn't\", 'even', 'use', 'enormous', 'blasts', 'of', 'sound', 'to', 'grab', 'my', 'attention', 'to', \"what's\", 'happening', 'on', 'screen', '(', 'Transformers', ',', \"I'm\", 'looking', 'at', 'you)', '.', \"It's\", 'not', 'trying', 'to', 'show', 'off', 'the', 'latest', 'CGI', 'techniques', ',', 'nor', 'did', 'it', 'offend', 'my', 'intelligence', 'with', 'dimwitted', 'dialogs', 'and', 'story', 'lines', 'that', 'are', 'simple', 'enough', 'I', \"could've\", 'figured', 'them', 'out', 'in', '3rd', 'grade', '(', 'boy', 'I', 'hate', 'those)', '.', '<br', '/><br', '/>I', 'just..', '.', 'watched', '.', 'Watched', ',', 'and', 'enjoyed', 'a', 'refreshingly', 'CREATIVE', 'storyline', 'unfold', 'before', 'my', 'eyes', '.', 'Sure', ',', 'I', 'may', 'have', 'known', 'what', 'was', 'going', 'to', 'happen', 'throughout', 'most', 'of', 'the', 'film', ',', 'but', 'it', 'makes', 'you', 'forget', 'that', '.', 'It', 'even', 'made', 'my', 'heart', 'twinge', 'at', 'some', 'parts', ',', 'but', 'the', 'most', 'important', 'aspect', 'I', 'noticed', 'is', 'that', 'I', 'left', 'the', 'theater', 'feeling', 'better', 'than', 'when', \"I'd\", 'gone', 'in.<br', '/><br', '/>It', 'truly', 'is', 'a', 'gem', '.', 'After', 'so', 'much', 'slush', 'this', 'summer', 'with', 'so', 'many', 'remakes', 'and', 'films', 'that', 'fell', 'short', 'of', 'my', 'expectations', ',', 'this', 'was', 'like', 'a', 'cold', 'sweet', 'cup', 'of', 'tea', 'to', 'cap', 'off', 'all', 'the', 'hard', 'work', \"I'd\", 'done', 'sitting', 'through', 'the', 'others', 'trying', 'to', 'come', 'out', 'of', 'them', 'with', 'my', \"money's\", 'worth.<br', '/><br', \"/>It's\", 'probably', 'not', 'for', 'everyone', ',', 'but', 'do', 'yourself', 'a', 'favor', ';', 'If', 'you', 'enjoy', 'fantasy', 'films', 'that', 'stand', 'the', 'test', 'of', 'time', 'alone', '(', 'Princess', 'Bride', ',', 'Black', 'Cauldron', ',', 'The', 'Dark', 'Crystal', ',', 'etc.', ')', 'then', 'you', 'should', 'really', 'see', 'this', 'movie', '.', 'This', 'little', 'diamond', 'is', 'finding', 'its', 'way', 'into', 'my', 'DVD', 'collection', 'the', 'moment', 'it', 'hits', 'stores', ',', 'you', 'can', 'trust', 'me', 'on', 'this.<br', '/><br', '/>Simply', 'wonderful', '.']\n",
            "Sample label: 2 \n",
            "\n",
            "Sample text: ['Bruce', 'Lee', 'was', 'a', 'great', 'martial', 'artist', ',', 'but', 'this', 'film', 'still', 'is', 'probably', 'one', 'of', 'the', 'worst', 'films', 'ever', 'made', '.', 'It', 'has', 'Bruce', 'Lee', 'die', 'as', 'the', 'result', 'of', 'falling', 'off', 'a', 'helicopter', 'after', 'being', 'hit', 'by', 'some', 'kind', 'of', 'a', 'ninja', 'knife', 'to', 'the', 'back', 'of', 'the', 'neck', 'but', 'it', \"doesn't\", 'explain', 'how', 'he', 'came', 'to', 'be', 'on', 'a', 'helicopter', 'since', 'the', 'prior', 'scene', 'has', 'him', 'near', 'but', 'not', 'on', 'the', 'helicopter', 'which', 'is', 'already', '200', 'feet', 'in', 'the', 'air', '.', 'It', 'just', 'gets', 'downright', 'absurd', 'from', 'then', ',', 'like', 'something', 'out', 'of', 'a', 'cheap', 'comic', 'book', '.', 'Maybe', 'the', 'idea', \"isn't\", 'so', 'rotten', 'but', 'it', \"isn't\", 'done', 'with', 'any', 'degree', 'of', 'artistry', 'from', 'a', 'film', 'making', 'point', 'of', 'view', '.', 'There', 'are', 'dozens', 'of', 'such', 'martial', 'arts', 'bombers', 'out', 'there', ',', 'usually', 'all', 'made', 'in', 'Hong', 'Kong', '.', 'I', 'think', 'that', 'Jean', 'Claude', 'van', 'Dam', 'improved', 'the', 'genre', 'with', 'adding', 'plausible', 'stories', 'in', 'his', 'films', 'and', 'having', 'film', 'makers', 'who', 'know', 'how', 'to', 'use', 'the', 'camera', '.', 'Even', 'Steven', \"Seagal's\", 'films', 'are', 'way', 'better', 'than', '90', 'percent', 'of', 'the', 'martial', 'arts', 'junk', 'movies', 'made', 'during', 'the', '1970s', 'and', 'early', '1980s', 'in', 'Hong', 'Kong', '.', \"'\", 'Game', 'of', 'Death', 'II', \"'\", 'falls', 'into', 'the', 'category', 'of', 'junk', 'cinema', 'in', 'my', 'opinion', ',', 'despite', 'Bruce', 'Lee', 'being', 'in', 'it', '.']\n",
            "Sample label: 1 \n",
            "\n",
            "Sample text: ['Intergalactic', 'criminal', 'Kol', '(', 'Ross', 'Hagen', ')', 'has', 'been', 'sentenced', 'to', 'death', 'and', 'awaits', 'execution', 'on', 'a', 'spaceship', 'designed', 'for', 'just', 'such', 'a', 'purpose', '.', 'But', 'tonight', \"there's\", 'going', 'to', 'be', 'a', 'jailbreak', ',', 'and', 'Kol', 'flees', 'on', 'a', 'conveniently-placed', 'escape', 'pod', 'and', 'flies', 'towards', 'Earth', '(', 'which', 'apparently', 'is', 'nearby)', '.', 'There', 'he', 'confronts', 'a', 'group', 'of', '\"', 'teenagers', '\"', '(', 'who', 'look', 'thirty', ')', 'and', 'a', 'game', 'warden', '(', 'John', 'Phillip', 'Law)', ',', 'who', 'help', 'protect', 'him', 'from', 'his', 'worst', 'nightmare..', '.', 'the', 'bounty', 'hunter', 'and', 'executioner', 'android', '(', 'or', 'more', 'properly', '\"', 'gynoid\"', ')', 'the', 'Alienator.<br', '/><br', '/>From', 'the', 'cover', 'of', 'the', 'box', ',', 'I', 'was', 'confident', 'this', 'was', 'going', 'to', 'be', 'an', 'awful', 'movie', '.', 'But', ',', 'as', 'awful', 'as', 'it', 'turned', 'out', 'to', 'be', ',', 'it', 'was', 'a', 'ton', 'of', 'fun', 'as', 'well', '(', 'probably', 'at', 'least', 'partially', 'because', 'I', 'was', 'watching', 'it', 'with', 'someone', 'who', 'happens', 'to', 'be', 'intensely', 'awesome)', '.', 'The', 'director', '(', 'Fred', 'Olen', 'Ray)', ',', 'who', 'has', 'specialized', 'in', 'making', 'over', 'one', 'hundred', 'low-grade', 'films', '(', 'most', 'notably', '\"', 'Hollywood', 'Chainsaw', 'Hookers\")', ',', 'does', 'what', 'he', 'does', 'best', 'and', 'throws', 'together', 'a', 'plot', 'that', 'only', 'half', 'makes', 'sense', 'and', 'gives', 'us', 'rudimentary', 'special', 'effects', '.', 'Bonus', ':', 'P.J', '.', 'Soles', 'appears', '(', 'as', '\"', 'Tara\")', ',', 'obviously', 'at', 'a', 'low', 'point', 'in', 'her', 'career.<br', '/><br', '/>Sure', ',', \"there's\", 'plot', 'holes', '.', 'Why', 'are', 'there', 'hillbilly', 'rednecks', 'in', 'California', '(', 'allegedly', 'Los', 'Angeles', 'County', 'if', 'I', 'understood', 'the', 'warden', 'correctly)', '.', \"What's\", 'up', 'with', 'the', 'space', \"woman's\", 'tacky', 'blouse', '?', 'Why', 'is', 'there', 'a', 'subplot', 'about', 'the', 'ship', 'captain', 'forcefully', 'trying', 'to', 'win', 'her', 'heart', 'when', 'this', 'story', 'goes', 'nowhere', '?', 'What', 'the', 'heck', 'is', '\"', 'Quadrant', '5\"', '?', 'How', 'does', 'chicken', 'wire', 'create', 'an', 'electromagnetic', 'field', 'that', 'will', 'short-circuit', 'an', 'android', ',', 'yet', 'land', 'mines', 'do', 'virtually', 'nothing', '?', 'Why', 'does', 'Kol', 'look', 'like', 'a', 'drunk', ',', 'Native', 'American', 'football', 'player', 'with', 'emphysema', '?', 'And', 'the', 'Lund', 'guy', '(', 'Robert', 'Clarke)..', '.', 'does', 'his', 'character', 'even', 'have', 'a', 'point', '?', 'Does', 'the', 'game', 'he', 'plays', 'with', 'the', 'captain', 'have', 'a', 'point', '?', 'Does', 'this', 'movie', 'have', 'a', 'point', '?', 'But', 'the', 'biggest', 'mystery', 'is', 'the', 'android', '(', 'or', 'gynoid', ')', 'the', 'Alienator', ',', 'played', 'by', 'Teagan', 'Clive', '.', 'What', 'is', 'an', '\"', 'alienator\"', '?', 'Why', 'does', 'it', 'look', 'like', 'Daryl', 'Hannah', 'from', '\"', 'Blade', 'Runner\"', ',', 'only', 'much', 'larger', '?', 'Because', ',', 'see', ',', 'if', 'something', 'is', 'a', 'cyborg', ',', \"it's\", 'part', 'human', '.', 'But', 'if', \"it's\", 'an', 'android', ',', \"it's\", 'all', 'machine', '.', 'This', 'was', 'an', 'android', ',', 'so', 'there', 'was', 'no', 'reason', 'to', 'make', 'it', 'look', 'human', '.', 'It', 'could', 'have', 'looked', 'like', 'anything', '.', 'Yet', ',', 'the', 'person', 'who', 'designed', 'her', 'made', 'her', 'the', 'size', 'of', 'a', 'linebacker', ',', 'with', 'David', \"Bowie's\", 'hair', 'and', 'a', 'leotard', 'that', 'shows', 'me', 'just', 'a', 'little', 'too', 'much', '.', 'If', \"you're\", 'going', 'to', 'make', 'a', 'female', 'android', ',', \"wouldn't\", 'the', 'purpose', 'be', 'to', 'have', 'her', 'be', 'seductive', 'and', 'lure', 'enemies', 'in', '?', 'Mission', 'not', 'accomplished', '.', 'They', 'say', 'beauty', 'comes', 'in', 'all', 'shapes', 'and', 'sizes', ',', 'but', 'I', 'think', 'I', 'found', 'a', 'huge', 'exception.<br', '/><br', '/>If', '\"', 'Mystery', 'Science', 'Theater', '3000', '\"', 'were', 'still', 'around', 'today', ',', 'this', 'film', 'would', 'be', 'on', 'a', 'very', 'short', 'list', 'of', 'movies', 'that', 'need', 'to', 'get', 'harangued.<br', '/><br', '/>Beyond', 'the', 'butt-nasty', 'Alienator', '(', 'sorry', ',', 'Teagan', ',', 'female', 'weight', 'lifters', 'are', 'gross', ')', 'the', 'film', 'is', 'alright', '.', 'Maybe', \"there's\", 'not', 'much', 'of', 'a', 'story', 'and', 'maybe', 'the', 'characters', \"aren't\", 'really', 'very', 'interesting', '.', 'And', 'maybe', 'the', 'scene', 'with', 'the', 'deer', 'is', 'incredibly', 'adorable', 'for', 'no', 'particular', 'reason', '--', 'what', 'use', 'does', 'a', 'killer', 'robot', 'have', 'with', 'a', 'deer', '?', 'But', 'overall', ',', 'I', 'actually', 'liked', 'the', 'movie', '.', 'I', \"won't\", 'be', 'pimping', 'it', 'out', 'to', 'my', 'friends', 'or', 'running', 'out', 'to', 'my', 'local', 'video', 'store', 'to', 'pick', 'up', 'the', 'latest', 'DVD', 'copy', '(', 'which', \"I'm\", 'sure', 'is', 'just', 'packed', 'with', 'amazing', 'special', 'features', '--', 'not)', '.', 'But', 'I', 'consider', 'seeing', 'this', 'movie', 'time', 'well', 'spent', 'and', 'look', 'forward', 'to', 'similar', 'adventures', 'in', 'the', 'future', '.']\n",
            "Sample label: 1 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "### DO NOT EDIT ###\n",
        "\n",
        "import torchtext\n",
        "import random\n",
        "\n",
        "def preprocess(review):\n",
        "    '''\n",
        "    Simple preprocessing function.\n",
        "    '''\n",
        "    res = []\n",
        "    for x in review.split(' '):\n",
        "        remove_beg=True if x[0] in {'(', '\"', \"'\"} else False\n",
        "        remove_end=True if x[-1] in {'.', ',', ';', ':', '?', '!', '\"', \"'\", ')'} else False\n",
        "        if remove_beg and remove_end: res += [x[0], x[1:-1], x[-1]]\n",
        "        elif remove_beg: res += [x[0], x[1:]]\n",
        "        elif remove_end: res += [x[:-1], x[-1]]\n",
        "        else: res += [x]\n",
        "    return res\n",
        "\n",
        "if __name__=='__main__':\n",
        "    train_data = torchtext.datasets.IMDB(root='.data', split='train')\n",
        "    #print(len(train_data))\n",
        "    train_data = list(train_data)\n",
        "    train_data = [(x[0], preprocess(x[1])) for x in train_data]\n",
        "    train_data, test_data = train_data[0:10000] + train_data[12500:12500+10000], train_data[10000:12500] + train_data[12500+10000:],\n",
        "\n",
        "    print('Num. Train Examples:', len(train_data))\n",
        "    print('Num. Test Examples:', len(test_data))\n",
        "\n",
        "    print(\"\\nSAMPLE DATA:\")\n",
        "    for x in random.sample(train_data, 5):\n",
        "        print('Sample text:', x[1])\n",
        "        print('Sample label:', x[0], '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kfg8RcyskyU"
      },
      "source": [
        "# Step 2: Create Dataloader [20 points]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvFX-iX5oq7T"
      },
      "source": [
        "## <font color='red'>TODO:</font> Define the Dataset Class [20 Points]\n",
        "\n",
        "In the following cell, we will define the <b>dataset</b> class. The dataset contains the tokenized data for your model. You need to implement the following functions:\n",
        "\n",
        "*   <b>` build_dictionary(self)`:</b>  <b>[10 points]</b> Creates the dictionaries `idx2word` and `word2idx`. You will represent each word in the dataset with a unique index, and keep track of this in these dictionaries. Use the hyperparameter `threshold` to control which words appear in the dictionary: a training word’s frequency should be `>= threshold` to be included in the dictionary.\n",
        "\n",
        "* <b>`convert_text(self)`:</b> Converts each review in the dataset to a list of indices, given by your `word2idx` dictionary. You should store this in the `textual_ids` variable, and the function does not return anything. If a word is not present in the  `word2idx` dictionary, you should use the `<UNK>` token for that word. Be sure to append the `<END>` token to the end of each review.\n",
        "\n",
        "*   <b>` get_text(self, idx) `:</b> Return the review at `idx` in the dataset as an array of indices corresponding to the words in the review. If the length of the review is less than `max_len`, you should pad the review with the `<PAD>` character up to the length of `max_len`. If the length is greater than `max_len`, then it should only return the first `max_len` words. The return type should be `torch.LongTensor`.\n",
        "\n",
        "*   <b>`get_label(self, idx) `</b>: Return the value `1` if the label for `idx` in the dataset is `positive`, and should return `0` if it is `negative`. The return type should be `torch.LongTensor`.\n",
        "\n",
        "*  <b> ` __len__(self) `:</b> Return the total number of reviews in the dataset as an `int`.\n",
        "\n",
        "*   <b>` __getitem__(self, idx)`:</b> <b>[10 points]</b> Return the (padded) text, and the label. The return type for both these items should be `torch.LongTensor`. You should use the ` get_label(self, idx) ` and ` get_text(self, idx) ` functions here.\n",
        "\n",
        "\n",
        "<b>Note:</b> You should convert all words to lower case in your functions.\n",
        "\n",
        "<font color='green'><b>Hint:</b> Make sure that you use instance variables such as `self.threshold` throughout your code, rather than the global variable `THRESHOLD` (defined later on). The variable `THRESHOLD` will not be known to the autograder, and the use of it within the class will cause an autograder error.</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1irMn3LX2YDB"
      },
      "outputs": [],
      "source": [
        "PAD = '<PAD>'\n",
        "END = '<END>'\n",
        "UNK = '<UNK>'\n",
        "\n",
        "from torch.utils import data\n",
        "from collections import defaultdict\n",
        "\n",
        "class TextDataset(data.Dataset):\n",
        "    def __init__(self, examples, split, threshold, max_len, idx2word=None, word2idx=None):\n",
        "        ### DO NOT EDIT ###\n",
        "\n",
        "        self.examples = examples\n",
        "        assert split in {'train', 'val', 'test'}\n",
        "        self.split = split\n",
        "        self.threshold = threshold\n",
        "        self.max_len = max_len\n",
        "\n",
        "        # Dictionaries\n",
        "        self.idx2word = idx2word\n",
        "        self.word2idx = word2idx\n",
        "        if split == 'train':\n",
        "            self.build_dictionary()\n",
        "        self.vocab_size = len(self.word2idx)\n",
        "\n",
        "        # Convert text to indices\n",
        "        self.textual_ids = []\n",
        "        self.convert_text()\n",
        "\n",
        "\n",
        "    def Frequency_each_word(self):\n",
        "      freq={}\n",
        "\n",
        "      for string in self.examples:\n",
        "        for word in string[1]:\n",
        "          word=word.lower()\n",
        "          if word in freq:\n",
        "            freq[word] += 1\n",
        "          else:\n",
        "            freq[word] = 1\n",
        "      return freq\n",
        "\n",
        "    def build_dictionary(self):\n",
        "        '''\n",
        "        Build the dictionaries idx2word and word2idx. This is only called when split='train', as these\n",
        "        dictionaries are passed in to the __init__(...) function otherwise. Be sure to use self.threshold\n",
        "        to control which words are assigned indices in the dictionaries.\n",
        "        Returns nothing.\n",
        "        '''\n",
        "        assert self.split == 'train'\n",
        "\n",
        "        # Don't change this\n",
        "        self.idx2word = {0:PAD, 1:END, 2: UNK}\n",
        "        self.word2idx = {PAD:0, END:1, UNK: 2}\n",
        "\n",
        "        ##### TODO #####\n",
        "        # Count the frequencies of all words in the training data (self.examples)\n",
        "        # Assign idx (starting from 3) to all words having word_freq >= self.threshold\n",
        "        # Make sure you call word.lower() on each word to convert it to lowercase\n",
        "        freq_word=self.Frequency_each_word()\n",
        "\n",
        "        idx=3\n",
        "\n",
        "        for string in self.examples:\n",
        "          for word in string[1]:\n",
        "            word=word.lower()\n",
        "\n",
        "            if freq_word[word]>=self.threshold:\n",
        "              if word not in self.word2idx:\n",
        "                self.idx2word[idx]=word\n",
        "                self.word2idx[word]=idx\n",
        "                idx=idx+1\n",
        "        pass\n",
        "\n",
        "    def convert_text(self):\n",
        "        '''\n",
        "        Convert each review in the dataset (self.examples) to a list of indices, given by self.word2idx.\n",
        "        Store this in self.textual_ids; returns nothing.\n",
        "        '''\n",
        "\n",
        "        #Converts each review in the dataset to a list of indices, given by your word2idx dictionary.\n",
        "        #You should store this in the textual_ids variable, and the function does not return anything.\n",
        "        #If a word is not present in the word2idx dictionary, you should use the <UNK> token for that word.\n",
        "        #Be sure to append the <END> token to the end of each review.\n",
        "\n",
        "        ##### TODO #####\n",
        "        # Remember to replace a word with the <UNK> token if it does not exist in the word2idx dictionary.\n",
        "        # Remember to append the <END> token to the end of each review.\n",
        "\n",
        "        review=[]\n",
        "        for string in self.examples:\n",
        "          for word in string[1]:\n",
        "            word=word.lower()\n",
        "            if word in self.word2idx:\n",
        "               review.append(self.word2idx[word])\n",
        "            else:\n",
        "              #append unk {PAD:0, END:1, UNK: 2}\n",
        "              review.append(2)\n",
        "          #append end\n",
        "          review.append(1)\n",
        "          self.textual_ids.append(review)\n",
        "          review=[]\n",
        "          #print(self.textual_ids)\n",
        "        pass\n",
        "\n",
        "    def get_text(self, idx):\n",
        "        '''\n",
        "        Return the review at idx as a long tensor (torch.LongTensor) of integers corresponding to the words in the review.\n",
        "        You may need to pad as necessary (see above).\n",
        "        '''\n",
        "\n",
        "        #Return the review at idx in the dataset as an array of indices corresponding to the words in the review.\n",
        "        #If the length of the review is less than max_len, you should pad the review with the <PAD> character up to the length of max_len.\n",
        "        #If the length is greater than max_len, then it should only return the first max_len words. The return type should be torch.LongTensor.\n",
        "\n",
        "        textual_ids_review=self.textual_ids[idx]\n",
        "\n",
        "        if(len(textual_ids_review)<self.max_len):\n",
        "          while(len(textual_ids_review)!=self.max_len):\n",
        "            #add padding\n",
        "            textual_ids_review.append(0)\n",
        "        elif(len(textual_ids_review)>self.max_len):\n",
        "          textual_ids_review=textual_ids_review[0:self.max_len]\n",
        "\n",
        "        return torch.LongTensor(textual_ids_review)\n",
        "\n",
        "\n",
        "    def get_label(self, idx):\n",
        "        '''\n",
        "        This function should return the value 1 if the label for idx in the dataset is 'positive',\n",
        "        and 0 if it is 'negative'. The return type should be torch.LongTensor.\n",
        "        '''\n",
        "        ##### TODO #####\n",
        "        if(self.examples[idx][0]=='neg'):\n",
        "          return torch.LongTensor([0]).squeeze()\n",
        "        else:\n",
        "          return torch.LongTensor([1]).squeeze()\n",
        "\n",
        "    def __len__(self):\n",
        "        '''\n",
        "        Return the number of reviews (int value) in the dataset\n",
        "        '''\n",
        "        ##### TODO #####\n",
        "\n",
        "        return len(self.examples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        '''\n",
        "        Return the review, and label of the review specified by idx.\n",
        "        '''\n",
        "        ##### TODO #####\n",
        "        #Return the (padded) text, and the label. The return type for both these items should be torch.LongTensor.\n",
        "        #You should use the get_label(self, idx) and get_text(self, idx) functions here.\n",
        "        return self.get_text(idx), self.get_label(idx)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    # reviews = [('pos', 'Your life is good when you have money, success and health'),('neg', 'Life is bad when you got not a lot'), ('neg', 'I dont like you')]\n",
        "    # data = [(x[0], preprocess(x[1])) for x in reviews]\n",
        "    # print(\"Sample dataset:\")\n",
        "    # for x in data: print(x)\n",
        "\n",
        "    # data[0][1][0:4]"
      ],
      "metadata": {
        "id": "nb2YjW_qF_Vh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxVxiGGbFJAj"
      },
      "source": [
        "##Sanity Check: Dataset Class\n",
        "\n",
        "The code below runs a sanity check for your `Dataset` class. The tests are similar to the hidden ones in Gradescope. However, note that passing the sanity check does <b>not</b> guarantee that you will pass the autograder; it is intended to help you debug."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bvHIZt8Z-RzK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2653df76-e580-4fd9-aebe-03413b25800e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample dataset:\n",
            "('pos', ['Your', 'life', 'is', 'good', 'when', 'you', 'have', 'money', ',', 'success', 'and', 'health'])\n",
            "('neg', ['Life', 'is', 'bad', 'when', 'you', 'got', 'not', 'a', 'lot'])\n",
            "\n",
            "--- TEST: idx2word and word2idx dictionaries ---\n",
            "\tthreshold: 1 \tmax_len: 3 \tPASSED \t\n",
            "\tthreshold: 2 \tmax_len: 3 \tPASSED \t\n",
            "\tthreshold: 3 \tmax_len: 3 \tPASSED \t\n",
            "\n",
            "--- TEST: len(dataset) ---\n",
            "\tPASSED\n",
            "\n",
            "--- TEST: __getitem__(self, idx) ---\n",
            "\tthreshold: 1 \tmax_len: 3 \tidx: 0 \tPASSED \t\n",
            "\tthreshold: 1 \tmax_len: 3 \tidx: 1 \tPASSED \t\n",
            "\tthreshold: 1 \tmax_len: 8 \tidx: 0 \tPASSED \t\n",
            "\tthreshold: 1 \tmax_len: 8 \tidx: 1 \tPASSED \t\n",
            "\tthreshold: 1 \tmax_len: 15 \tidx: 0 \tPASSED \t\n",
            "\tthreshold: 1 \tmax_len: 15 \tidx: 1 \tPASSED \t\n",
            "\tthreshold: 2 \tmax_len: 3 \tidx: 0 \tPASSED \t\n",
            "\tthreshold: 2 \tmax_len: 3 \tidx: 1 \tPASSED \t\n",
            "\tthreshold: 2 \tmax_len: 8 \tidx: 0 \tPASSED \t\n",
            "\tthreshold: 2 \tmax_len: 8 \tidx: 1 \tPASSED \t\n",
            "\tthreshold: 2 \tmax_len: 15 \tidx: 0 \tPASSED \t\n",
            "\tthreshold: 2 \tmax_len: 15 \tidx: 1 \tPASSED \t\n",
            "\tthreshold: 3 \tmax_len: 3 \tidx: 0 \tPASSED \t\n",
            "\tthreshold: 3 \tmax_len: 3 \tidx: 1 \tPASSED \t\n",
            "\tthreshold: 3 \tmax_len: 8 \tidx: 0 \tPASSED \t\n",
            "\tthreshold: 3 \tmax_len: 8 \tidx: 1 \tPASSED \t\n",
            "\tthreshold: 3 \tmax_len: 15 \tidx: 0 \tPASSED \t\n",
            "\tthreshold: 3 \tmax_len: 15 \tidx: 1 \tPASSED \t\n"
          ]
        }
      ],
      "source": [
        "### DO NOT EDIT ###\n",
        "\n",
        "def sanityCheckDataSet():\n",
        "    #\tRead in the sample corpus\n",
        "    reviews = [('pos', 'Your life is good when you have money, success and health'),\n",
        "               ('neg', 'Life is bad when you got not a lot')]\n",
        "    data = [(x[0], preprocess(x[1])) for x in reviews]\n",
        "    print(\"Sample dataset:\")\n",
        "    for x in data: print(x)\n",
        "\n",
        "    thresholds = [1,2,3]\n",
        "    print('\\n--- TEST: idx2word and word2idx dictionaries ---') # max_len does not matter for this test\n",
        "    correct = [[',', '<END>', '<PAD>', '<UNK>', 'a', 'and', 'bad', 'good', 'got', 'have', 'health', 'is', 'life', 'lot', 'money', 'not', 'success', 'when', 'you', 'your'], ['<END>', '<PAD>', '<UNK>', 'is', 'life', 'when', 'you'], ['<END>', '<PAD>', '<UNK>']]\n",
        "    for i in range(len(thresholds)):\n",
        "        dataset = TextDataset(data, 'train', threshold=thresholds[i], max_len=3)\n",
        "\n",
        "        has_passed, message = True, ''\n",
        "        if has_passed and (dataset.vocab_size != len(dataset.word2idx) or dataset.vocab_size != len(dataset.idx2word)):\n",
        "            has_passed, message = False, 'dataset.vocab_size (' + str(dataset.vocab_size) + ') must be the same length as dataset.word2idx (' + str(len(dataset.word2idx)) + ') and dataset.idx2word ('+str(len(dataset.idx2word)) +').'\n",
        "        if has_passed and (dataset.vocab_size != len(correct[i])):\n",
        "            has_passed, message = False, 'Your vocab size is incorrect. Expected: ' + str(len(correct[i])) + '\\tGot: ' + str(dataset.vocab_size)\n",
        "        if has_passed and sorted(list(dataset.idx2word.keys())) != list(range(0, dataset.vocab_size)):\n",
        "            has_passed, message = False, 'dataset.idx2word must have keys ranging from 0 to dataset.vocab_size-1. Keys in your dataset.idx2word: ' + str(sorted(list(dataset.idx2word.keys())))\n",
        "        if has_passed and sorted(list(dataset.word2idx.keys())) != correct[i]:\n",
        "            has_passed, message = False, 'Your dataset.word2idx has incorrect keys. Expected: ' + str(correct[i]) + '\\tGot: ' + str(sorted(list(dataset.word2idx.keys())))\n",
        "        if has_passed: # Check that word2idx and idx2word are consistent\n",
        "            widx = sorted(list(dataset.word2idx.items()))\n",
        "            idxw = sorted(list([(v,k) for k,v in dataset.idx2word.items()]))\n",
        "            if not (len(widx) == len(idxw) and all([widx[q] == idxw[q] for q in range(len(widx))])):\n",
        "                has_passed, message = False, 'Your dataset.word2idx and dataset.idx2word are not consistent. dataset.idx2word: ' + str(dataset.idx2word) + '\\tdataset.word2idx: ' + str(dataset.word2idx)\n",
        "\n",
        "        status = 'PASSED' if has_passed else 'FAILED'\n",
        "        print('\\tthreshold:', thresholds[i], '\\tmax_len:', 3, '\\t'+status, '\\t'+message)\n",
        "\n",
        "    print('\\n--- TEST: len(dataset) ---')\n",
        "    has_passed = len(dataset) == 2\n",
        "    if has_passed: print('\\tPASSED')\n",
        "    else: print('\\tlen(dataset) is incorrect. Expected: 2\\tGot: ' + str(len(dataset)))\n",
        "\n",
        "    print('\\n--- TEST: __getitem__(self, idx) ---')\n",
        "    max_lens = [3,8,15]\n",
        "    idxes = [0,1]\n",
        "    combos = [{'threshold': t, 'max_len': m, 'idx': idx} for t in thresholds for m in max_lens for idx in idxes]\n",
        "    correct = [(torch.tensor([3, 4, 5]), torch.tensor(1)), (torch.tensor([ 4,  5, 15]), torch.tensor(0)), (torch.tensor([ 3,  4,  5,  6,  7,  8,  9, 10]), torch.tensor(1)), (torch.tensor([ 4,  5, 15,  7,  8, 16, 17, 18]), torch.tensor(0)), (torch.tensor([ 3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14,  1,  0,  0]), torch.tensor(1)), (torch.tensor([ 4,  5, 15,  7,  8, 16, 17, 18, 19,  1,  0,  0,  0,  0,  0]), torch.tensor(0)), (torch.tensor([2, 3, 4]), torch.tensor(1)), (torch.tensor([3, 4, 2]), torch.tensor(0)), (torch.tensor([2, 3, 4, 2, 5, 6, 2, 2]), torch.tensor(1)), (torch.tensor([3, 4, 2, 5, 6, 2, 2, 2]), torch.tensor(0)), (torch.tensor([2, 3, 4, 2, 5, 6, 2, 2, 2, 2, 2, 2, 1, 0, 0]), torch.tensor(1)), (torch.tensor([3, 4, 2, 5, 6, 2, 2, 2, 2, 1, 0, 0, 0, 0, 0]), torch.tensor(0)), (torch.tensor([2, 2, 2]), torch.tensor(1)), (torch.tensor([2, 2, 2]), torch.tensor(0)), (torch.tensor([2, 2, 2, 2, 2, 2, 2, 2]), torch.tensor(1)), (torch.tensor([2, 2, 2, 2, 2, 2, 2, 2]), torch.tensor(0)), (torch.tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 0]), torch.tensor(1)), (torch.tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 0, 0, 0, 0]), torch.tensor(0))]\n",
        "    for i in range(len(combos)):\n",
        "        combo = combos[i]\n",
        "        dataset = TextDataset(data, 'train', threshold=combo['threshold'], max_len=combo['max_len'])\n",
        "        returned = dataset.__getitem__(combo['idx'])\n",
        "\n",
        "        has_passed, message = True, ''\n",
        "        if has_passed and len(returned) != 2:\n",
        "            has_passed, message = False, 'dataset.__getitem__(idx) must return 2 things. Got ' + str(len(returned)) +' things instead.'\n",
        "        if has_passed and (type(returned[0]) != torch.Tensor or type(returned[1]) != torch.Tensor):\n",
        "            has_passed, message = False, 'Both returns must be of type torch.Tensor. Got: (' + str(type(returned[0])) + ', ' + str(type(returned[1])) + ')'\n",
        "        if has_passed and (returned[0].shape != correct[i][0].shape):\n",
        "            has_passed, message = False, 'Shape of first return is incorrect. Expected: ' + str(correct[i][0].shape) + '.\\tGot: ' + str(returned[0].shape)\n",
        "        if has_passed and (returned[1].shape != correct[i][1].shape):\n",
        "            has_passed, message = False, 'Shape of second return is incorrect. Expected: ' + str(correct[i][1].shape) + '.\\tGot: ' + str(returned[1].shape) + '\\n\\t\\tHint: torch.Size([]) means that the tensor should be dimensionless (just a number). Try squeezing your result.'\n",
        "        if has_passed and (returned[1] != correct[i][1]):\n",
        "            has_passed, message = False, 'Label (second return) is incorrect. Expected: ' + str(correct[i][1]) + '.\\tGot: ' + str(returned[1])\n",
        "        if has_passed:\n",
        "            correct_padding_idxes, your_padding_idxes = torch.where(correct[i][0] == 0)[0], torch.where(returned[0] == dataset.word2idx[PAD])[0]\n",
        "            if not (correct_padding_idxes.shape == your_padding_idxes.shape and torch.all(correct_padding_idxes == your_padding_idxes)):\n",
        "                has_passed, message = False, 'Padding is not correct. Expected padding indxes: ' + str(correct_padding_idxes) + '.\\tYour padding indexes: ' + str(your_padding_idxes)\n",
        "\n",
        "        status = 'PASSED' if has_passed else 'FAILED'\n",
        "        print('\\tthreshold:', combo['threshold'], '\\tmax_len:', combo['max_len'] , '\\tidx:', combo['idx'], '\\t'+status, '\\t'+message)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    sanityCheckDataSet()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CR4VQbQCNZH6"
      },
      "source": [
        "The following cell builds the dataset on the IMDb movie reviews and prints an example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "HSxpGXj6ml9N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f02039ed-19b4-4081-c516-02e7e12f121e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size: 19002 \n",
            "\n",
            "Example text:\n",
            "['This', 'grainy', 'film', 'has', 'a', 'cult', 'following', 'and', 'one', 'of', 'those', 'word-of-mouth', 'features', 'you', 'just', 'had', 'to', 'see', '.', 'Maybe', 'hard', 'to', 'believe', ',', 'but', 'there', 'is', 'a', 'rural', 'community', 'in', 'southwest', 'Arkansas', ',', 'Fouke', ',', 'that', 'knows', 'the', 'legend', 'is', 'true', '.', 'This', 'tale', 'is', 'told', 'in', 'documentary-style', 'narrated', 'by', 'Vern', 'Stierman', 'and', 'filmed', 'in', 'actual', 'locations', 'talking', 'to', 'actual', 'folks', 'involved', '.', 'The', 'legend', 'changes', 'with', 'the', 'telling', ',', 'but', 'during', 'the', 'late', '60s', 'and', 'most', 'of', 'the', '70s', 'the', 'surrounding', 'area', 'of', 'Fouke', 'was', 'visited', 'by', 'a', 'Bigfoot-like', 'creature', 'that', 'traveled', 'along', 'Boggy', 'Creek', '.', 'Long', 'limbed', 'with', 'three', 'toes', 'and', 'standing', 'over', '7', 'foot', 'tall', ',', 'this', 'hirsute', 'creature', 'periodically', 'caused', 'damage', 'and', 'frightened', 'the', \"'\", 'bejeebers', \"'\", 'out', 'of', 'most', 'of', 'the', 'community', '.', 'I', 'personally', 'crossed', 'over', 'the', 'small', 'Boggy', 'Creek', 'bridge', 'in', '1974', ',', 'and', 'yes', 'the', 'hair', 'on', 'the', 'back', 'of', 'my', 'neck', 'did', 'rise', '.', 'Of', 'course', 'it', 'was', 'about', '1', 'a.m', '.', 'in', 'the', 'rain', '.', 'By', 'the', 'time', 'I', 'arrived', 'in', 'Shreveport', ',', 'I', 'was', 'laughing', '.']\n",
            "tensor([   36,   497,   157,   103,    41,  3329,   761,    91,   253,    11,\n",
            "          221,     2,  3375,   267,   162,    48,    34,    49,    24,  1513,\n",
            "          532,    34,   524,    38,   180,   258,    55,    41,  8407,  4889,\n",
            "           22, 18379,     2,    38,     2,    38,    15,  1710,    13,   552,\n",
            "           55,   204,    24,    36,  3764,    55,   599,    22,     2, 13878,\n",
            "           28,     2,     2,    91,  1302,    22,   628,  1466,  2498,    34,\n",
            "          628,  5717,   885,    24,    13,   552,  6623,   105,    13,  1697,\n",
            "           38,   180,   318,    13,  1264,  6693,    91,   345,    11,    13,\n",
            "         1906,    13,   964,  1436,    11,     2,    19,  4518,    28,    41,\n",
            "            2,  7945,    15, 13103,  1030, 16059, 10519,    24,   718,     2,\n",
            "          105,  1860, 14151,    91,  3031,   464,  1537,  7539,  3531,    38,\n",
            "           36,     2,  7945,  8784,  1104,  1318,    91, 11658,    13,   610,\n",
            "            2,   610,   325,    11,   345,    11,    13,  4889,    24,     3,\n",
            "         4103,  9039,   464,    13,   583, 16059, 10519,  8915,    22, 14925,\n",
            "           38,    91,  1372,    13,  1185,    80,    13,   734,    11,     7])\n",
            "\n",
            "Example label:\n",
            "1\n",
            "tensor(1)\n"
          ]
        }
      ],
      "source": [
        "### DO NOT EDIT ###\n",
        "\n",
        "if __name__=='__main__':\n",
        "    train_dataset = TextDataset(train_data, 'train', threshold=10, max_len=150)\n",
        "    print('Vocab size:', train_dataset.vocab_size, '\\n')\n",
        "\n",
        "    randidx = random.randint(0, len(train_dataset)-1)\n",
        "    text, label = train_dataset[randidx]\n",
        "    print('Example text:')\n",
        "    print(train_data[randidx][1])\n",
        "    print(text)\n",
        "    print('\\nExample label:')\n",
        "    print(train_data[randidx][0])\n",
        "    print(label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_4FFhulaAod"
      },
      "source": [
        "# Step 3: Train a Convolutional Neural Network (CNN) [40 points]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcSKydlClwOC"
      },
      "source": [
        "## <font color='red'>TODO:</font> Define the CNN Model [20 points]\n",
        "Here you will define your convolutional neural network for text classification. We provide you with the CNN class, you need to fill in parts of the `__init__(...)` and `forward(...)` functions. Each of these functions is worth 10 points.\n",
        "\n",
        "We have provided you with instructions and hints in the comments. In particular, pay attention to the desired shapes; you may find it helpful to print the shape of the tensors as you code. It may also help to keep PyTorch documentation open for the modules & functions you are using, since they describe input and output dimensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0ztuy2hUaAof"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, out_channels, filter_heights, stride, dropout, num_classes, pad_idx):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        ##### TODO #####\n",
        "        # Create an embedding layer (https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html)\n",
        "        #   to represent the words in your vocabulary. Make sure to use vocab_size, embed_size, and pad_idx here.\n",
        "\n",
        "        self.emb=nn.Embedding(num_embeddings=vocab_size, embedding_dim=embed_size, padding_idx=pad_idx)\n",
        "\n",
        "\n",
        "        # Define multiple Convolution layers (nn.Conv2d) with filter (kernel) size [filter_height, embed_size] based on your\n",
        "        #   different filter_heights.\n",
        "        # Input channels will be 1 and output channels will be out_channels (these many different filters will be trained\n",
        "        #   for each convolution layer)\n",
        "        # If you want, you can store a list of modules inside nn.ModuleList.\n",
        "        # Note: even though your conv layers are nn.Conv2d, we are doing a 1d convolution since we are only moving the filter\n",
        "        #   in one direction\n",
        "\n",
        "        self.layers=nn.ModuleList([nn.Conv2d(in_channels=1, out_channels=out_channels, kernel_size=(filter, embed_size), stride=stride)\n",
        "        for filter in filter_heights])\n",
        "\n",
        "\n",
        "        # Create a dropout layer (nn.Dropout) using dropout\n",
        "\n",
        "        self.fc1=nn.Dropout(dropout)\n",
        "\n",
        "        # Define a linear layer (nn.Linear) that consists of  units\n",
        "        #   and takes as input the concatenated output for all cnn layers (out_channels * num_of_cnn_layers units)\n",
        "\n",
        "        self.fc2=nn.Linear(out_channels * len(filter_heights), num_classes)\n",
        "\n",
        "    def forward(self, texts):\n",
        "        \"\"\"\n",
        "        texts: LongTensor [batch_size, max_len]\n",
        "\n",
        "        Returns output: Tensor [batch_size, num_classes]\n",
        "        \"\"\"\n",
        "        ##### TODO #####\n",
        "\n",
        "        # Pass texts through your embedding layer to convert from word ids to word embeddings\n",
        "        #   Resulting: shape: [batch_size, max_len, embed_size]\n",
        "\n",
        "        # Input to conv should have 1 channel. Take a look at torch's unsqueeze() function\n",
        "        #   Resulting shape: [batch_size, 1, MAX_LEN, embed_size]\n",
        "\n",
        "        # Pass these texts to each of your conv layers and compute their output as follows:\n",
        "        #   Your cnn output will have shape [batch_size, out_channels, *, 1] where * depends on filter_height and stride\n",
        "        #   Convert to shape [batch_size, out_channels, *] (see torch's squeeze() function)\n",
        "        #   Apply non-linearity on it (F.relu() is a commonly used one. Feel free to try others)\n",
        "        #   Take the max value across last dimension to have shape [batch_size, out_channels]\n",
        "        # Concatenate (torch.cat) outputs from all your cnns [batch_size, (out_channels*num_of_cnn_layers)]\n",
        "\n",
        "        # Let's understand what you just did:\n",
        "        #   Since each cnn is of different filter_height, it will look at different number of words at a time\n",
        "        #     So, a filter_height of 3 means your cnn looks at 3 words (3-grams) at a time and tries to extract some information from it\n",
        "        #   Each cnn will learn out_channels number of features from the words it sees at a time\n",
        "        #   Then you applied a non-linearity and took the max value for all channels\n",
        "        #     You are essentially trying to find important n-grams from the entire text\n",
        "        # Everything happens on a batch simultaneously hence you have that additional batch_size as the first dimension\n",
        "\n",
        "        # Apply dropout\n",
        "\n",
        "        # Pass your output through the linear layer and return its output\n",
        "        #   Resulting shape: [batch_size, num_classes]\n",
        "\n",
        "        ##### NOTE: Do not apply a sigmoid or softmax to the final output - done in training method!\n",
        "\n",
        "        out=self.emb(texts)\n",
        "        out=out.unsqueeze(1)\n",
        "\n",
        "        layers_out=[F.relu(layer(out)).squeeze(3) for layer in self.layers]\n",
        "\n",
        "        max_pool=[F.max_pool1d(layer,layer.shape[2]).squeeze(2) for layer in layers_out]\n",
        "\n",
        "        out=self.fc1(torch.cat(max_pool, dim=1))\n",
        "        out=self.fc2(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mVE_ujfnh0w"
      },
      "source": [
        "##Sanity Check: CNN Model\n",
        "\n",
        "The code below runs a sanity check for your `CNN` class. The tests are similar to the hidden ones in Gradescope. However, note that passing the sanity check does <b>not</b> guarantee that you will pass the autograder; it is intended to help you debug."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "yy9oF6qUUHvV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cd1c975-4c74-4cd7-c5a1-aa455cd6fd42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- TEST: Number of Model Parameters (tests __init__(...)) ---\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 22434\tYour Num. Params: 22434\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 22531\tYour Num. Params: 22531\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 22434\tYour Num. Params: 22434\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 22531\tYour Num. Params: 22531\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 23874\tYour Num. Params: 23874\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 23939\tYour Num. Params: 23939\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 23874\tYour Num. Params: 23874\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 23939\tYour Num. Params: 23939\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 41730\tYour Num. Params: 41730\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 42115\tYour Num. Params: 42115\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 41730\tYour Num. Params: 41730\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 42115\tYour Num. Params: 42115\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 47490\tYour Num. Params: 47490\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 47747\tYour Num. Params: 47747\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 47490\tYour Num. Params: 47490\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 47747\tYour Num. Params: 47747\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 44578\tYour Num. Params: 44578\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 44675\tYour Num. Params: 44675\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 44578\tYour Num. Params: 44578\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 44675\tYour Num. Params: 44675\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 47554\tYour Num. Params: 47554\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 47619\tYour Num. Params: 47619\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 47554\tYour Num. Params: 47554\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 47619\tYour Num. Params: 47619\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 82306\tYour Num. Params: 82306\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 82691\tYour Num. Params: 82691\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 82306\tYour Num. Params: 82306\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 82691\tYour Num. Params: 82691\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 94210\tYour Num. Params: 94210\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 94467\tYour Num. Params: 94467\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 94210\tYour Num. Params: 94210\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 94467\tYour Num. Params: 94467\n",
            "\n",
            "--- TEST: Output shape of forward(...) ---\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n"
          ]
        }
      ],
      "source": [
        "### DO NOT EDIT ###\n",
        "\n",
        "count_parameters = lambda model: sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "def sanityCheckModel(all_test_params, NN, expected_outputs, init_or_forward, data_loader):\n",
        "    print('--- TEST: ' + ('Number of Model Parameters (tests __init__(...))' if init_or_forward=='init' else 'Output shape of forward(...)') + ' ---')\n",
        "\n",
        "    if init_or_forward == \"forward\":\n",
        "        # Reading the first batch of data for testing\n",
        "        for texts_, labels_ in data_loader:\n",
        "            texts_batch, labels_batch = texts_, labels_\n",
        "            break\n",
        "\n",
        "    for tp_idx, (test_params, expected_output) in enumerate(zip(all_test_params, expected_outputs)):\n",
        "        if init_or_forward == \"forward\":\n",
        "            batch_size = test_params['batch_size']\n",
        "            texts = texts_batch[:batch_size]\n",
        "\n",
        "        # Construct the student model\n",
        "        tps = {k:v for k, v in test_params.items() if k != 'batch_size'}\n",
        "        stu_nn = NN(**tps)\n",
        "\n",
        "        if init_or_forward == \"forward\":\n",
        "            with torch.no_grad():\n",
        "                stu_out = stu_nn(texts)\n",
        "            ref_out_shape = expected_output\n",
        "\n",
        "            has_passed = torch.is_tensor(stu_out)\n",
        "            if not has_passed: msg = 'Output must be a torch.Tensor; received ' + str(type(stu_out))\n",
        "            else:\n",
        "                has_passed = stu_out.shape == ref_out_shape\n",
        "                msg = 'Your Output Shape: ' + str(stu_out.shape)\n",
        "\n",
        "\n",
        "            status = 'PASSED' if has_passed else 'FAILED'\n",
        "            message = '\\t' + status + \"\\t Init Input: \" + str({k:v for k,v in tps.items()}) + '\\tForward Input Shape: ' + str(texts.shape) + '\\tExpected Output Shape: ' + str(ref_out_shape) + '\\t' + msg\n",
        "            print(message)\n",
        "        else:\n",
        "            stu_num_params = count_parameters(stu_nn)\n",
        "            ref_num_params = expected_output\n",
        "            comparison_result = (stu_num_params == ref_num_params)\n",
        "\n",
        "            status = 'PASSED' if comparison_result else 'FAILED'\n",
        "            message = '\\t' + status + \"\\tInput: \" + str({k:v for k,v in test_params.items()}) + ('\\tExpected Num. Params: ' + str(ref_num_params) + '\\tYour Num. Params: '+ str(stu_num_params))\n",
        "            print(message)\n",
        "\n",
        "        del stu_nn\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Test init\n",
        "    inputs = [{'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}]\n",
        "    expected_outputs = [22434, 22531, 22434, 22531, 23874, 23939, 23874, 23939, 41730, 42115, 41730, 42115, 47490, 47747, 47490, 47747, 44578, 44675, 44578, 44675, 47554, 47619, 47554, 47619, 82306, 82691, 82306, 82691, 94210, 94467, 94210, 94467]\n",
        "\n",
        "    sanityCheckModel(inputs, CNN, expected_outputs, \"init\", None)\n",
        "    print()\n",
        "\n",
        "    # Test forward\n",
        "    inputs = [{'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}]\n",
        "    expected_outputs = [torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2])]\n",
        "    sanity_dataset = TextDataset(train_data, 'train', 5, 150)\n",
        "    sanity_loader = torch.utils.data.DataLoader(sanity_dataset, batch_size=50, shuffle=True, num_workers=2, drop_last=True)\n",
        "\n",
        "    sanityCheckModel(inputs, CNN, expected_outputs, \"forward\", sanity_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FupiBIfasCu_"
      },
      "source": [
        "## Train CNN Model\n",
        "\n",
        "First, we initialize the train and test <b>dataloaders</b>. A dataloader is responsible for providing batches of data to your model. Notice how we first instantiate datasets for the train and test data, and that we use the training vocabulary for both.\n",
        "\n",
        "You do not need to edit this cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "J2QYl334n9ON"
      },
      "outputs": [],
      "source": [
        "if __name__=='__main__':\n",
        "    THRESHOLD = 5 # Don't change this\n",
        "    MAX_LEN = 200 # Don't change this\n",
        "    BATCH_SIZE = 32 # Feel free to try other batch sizes\n",
        "\n",
        "    train_dataset = TextDataset(train_data, 'train', THRESHOLD, MAX_LEN)\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, drop_last=True)\n",
        "\n",
        "    test_dataset = TextDataset(test_data, 'test', THRESHOLD, MAX_LEN, train_dataset.idx2word, train_dataset.word2idx)\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=1, drop_last=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvsctopWmeoY"
      },
      "source": [
        "Now we provide you with a function that takes your model and trains it on the data.\n",
        "\n",
        "You do not need to edit this cell. However, you may want to write code to save your model periodically, as Colab connections are not permanent. See the tutorial here if you wish to do this: https://pytorch.org/tutorials/beginner/saving_loading_models.html."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "LD-Jj2rUFOzr"
      },
      "outputs": [],
      "source": [
        "### DO NOT EDIT ###\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "def train_model(model, num_epochs, data_loader, optimizer, criterion):\n",
        "    print('Training Model...')\n",
        "    model.train()\n",
        "    for epoch in tqdm(range(num_epochs)):\n",
        "        epoch_loss = 0\n",
        "        epoch_acc = 0\n",
        "        for texts, labels in data_loader:\n",
        "            texts = texts.to(DEVICE) # shape: [batch_size, MAX_LEN]\n",
        "            labels = labels.to(DEVICE) # shape: [batch_size]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output = model(texts)\n",
        "            acc = accuracy(output, labels)\n",
        "\n",
        "            loss = criterion(output, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        print('[TRAIN]\\t Epoch: {:2d}\\t Loss: {:.4f}\\t Train Accuracy: {:.2f}%'.format(epoch+1, epoch_loss/len(data_loader), 100*epoch_acc/len(data_loader)))\n",
        "    print('Model Trained!\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyIZS0WUhFA6"
      },
      "source": [
        "Here are some other helper functions we will need."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "zVP2scuyhG5f"
      },
      "outputs": [],
      "source": [
        "### DO NOT EDIT ###\n",
        "\n",
        "def accuracy(output, labels):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch\n",
        "    output: Tensor [batch_size, n_classes]\n",
        "    labels: LongTensor [batch_size]\n",
        "    \"\"\"\n",
        "    preds = output.argmax(dim=1) # find predicted class\n",
        "    correct = (preds == labels).sum().float() # convert into float for division\n",
        "    acc = correct / len(labels)\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjvX5c6Isw9e"
      },
      "source": [
        "Now you can instantiate your model. We provide you with some recommended hyperparameters; you should be able to get the desired accuracy with these, but feel free to play around with them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "M5UtdjGDuBty",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c6da867-723c-4b76-83e4-b796569ccd08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 3,879,746 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "if __name__=='__main__':\n",
        "    cnn_model = CNN(vocab_size = train_dataset.vocab_size, # Don't change this\n",
        "                embed_size = 128,\n",
        "                out_channels = 64,\n",
        "                filter_heights = [2, 3, 4],\n",
        "                stride = 1,\n",
        "                dropout = 0.5,\n",
        "                num_classes = 2, # Don't change this\n",
        "                pad_idx = train_dataset.word2idx[PAD]) # Don't change this\n",
        "\n",
        "    # Put your model on the device (cuda or cpu)\n",
        "    cnn_model = cnn_model.to(DEVICE)\n",
        "\n",
        "    print('The model has {:,d} trainable parameters'.format(count_parameters(cnn_model)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeHpqw6zvkhI"
      },
      "source": [
        "Next, we create the **criterion**, which is our loss function: it is a measure of how well the model matches the empirical distribution of the data. We use cross-entropy loss (https://en.wikipedia.org/wiki/Cross_entropy).\n",
        "\n",
        "We also define the **optimizer**, which performs gradient descent. We use the Adam optimizer (https://arxiv.org/pdf/1412.6980.pdf), which has been shown to work well on these types of models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "FoeyQL4PoNoH"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "if __name__=='__main__':\n",
        "    LEARNING_RATE = 5e-4 # Feel free to try other learning rates\n",
        "\n",
        "    # Define the loss function\n",
        "    criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
        "\n",
        "    # Define the optimizer\n",
        "    optimizer = optim.Adam(cnn_model.parameters(), lr=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RopLfAJ9wOHN"
      },
      "source": [
        "Finally, we can train the model. If the model is implemented correctly and you're using the GPU, this cell should take around <b>4 minutes</b> (or less). Feel free to change the number of epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "lPOs1FifoNoN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281,
          "referenced_widgets": [
            "b45670bfd5274a0287a2b67d963e80f3",
            "13773b59fd91438b90b345809b87a65d",
            "54f8f34e92d94cdca30496ce06249e39",
            "fc49e9d5724e44b5a5bf6b4d18017b68",
            "eff426beaa51478ab57e32da45a975bf",
            "e8281df0737e4d188c988552e8d7c077",
            "10ec98051c3448ea845babbd907b8f5e",
            "d814f779d2bb454f87f5ad95f5eb3d1e",
            "8c80eb1efa1e448eab81304a5d3e5955",
            "f7721712e2c04b6fb31a8331d0e4ef45",
            "b25960dc9f6a4cc28fe19997f7a2e2ec"
          ]
        },
        "outputId": "1acdf190-d483-4a85-9870-d4632405722f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b45670bfd5274a0287a2b67d963e80f3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]\t Epoch:  1\t Loss: 0.0070\t Train Accuracy: 99.67%\n",
            "[TRAIN]\t Epoch:  2\t Loss: 0.0000\t Train Accuracy: 100.00%\n",
            "[TRAIN]\t Epoch:  3\t Loss: 0.0000\t Train Accuracy: 100.00%\n",
            "[TRAIN]\t Epoch:  4\t Loss: 0.0000\t Train Accuracy: 100.00%\n",
            "[TRAIN]\t Epoch:  5\t Loss: 0.0000\t Train Accuracy: 100.00%\n",
            "[TRAIN]\t Epoch:  6\t Loss: 0.0000\t Train Accuracy: 100.00%\n",
            "[TRAIN]\t Epoch:  7\t Loss: 0.0000\t Train Accuracy: 100.00%\n",
            "[TRAIN]\t Epoch:  8\t Loss: 0.0000\t Train Accuracy: 100.00%\n",
            "[TRAIN]\t Epoch:  9\t Loss: 0.0000\t Train Accuracy: 100.00%\n",
            "[TRAIN]\t Epoch: 10\t Loss: 0.0000\t Train Accuracy: 100.00%\n",
            "Model Trained!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "if __name__=='__main__':\n",
        "    N_EPOCHS = 10 # Feel free to change this\n",
        "\n",
        "    # train model for N_EPOCHS epochs\n",
        "    train_model(cnn_model, N_EPOCHS, train_loader, optimizer, criterion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-OJbZ72t6Yq"
      },
      "source": [
        "## Evaluate CNN Model [20 points]\n",
        "\n",
        "Now that we have trained a model for text classification, it is time to evaluate it. We have provided you with a function to do this; you do not need to modify anything.\n",
        "\n",
        "To pass the autograder for the CNN, you will need to achieve **82% accuracy** on the hidden test set on Gradescope. Note that the Gradescope test set is very similar, and the accuracies between the two datasets should be comparable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "vTiiYDZIF--7"
      },
      "outputs": [],
      "source": [
        "### DO NOT EDIT ###\n",
        "\n",
        "import random\n",
        "\n",
        "def evaluate(model, data_loader, criterion, use_tqdm=False):\n",
        "    print('Evaluating performance on the test dataset...')\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    all_predictions = []\n",
        "    print(\"\\nSOME PREDICTIONS FROM THE MODEL:\")\n",
        "    iterator = tqdm(data_loader) if use_tqdm else data_loader\n",
        "    total = 0\n",
        "    for texts, labels in iterator:\n",
        "        bs = texts.shape[0]\n",
        "        total += bs\n",
        "        texts = texts.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "\n",
        "        output = model(texts)\n",
        "        acc = accuracy(output, labels) * len(labels)\n",
        "        pred = output.argmax(dim=1)\n",
        "        all_predictions.append(pred)\n",
        "\n",
        "        loss = criterion(output, labels) * len(labels)\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "\n",
        "        if random.random() < 0.0015 and bs == 1:\n",
        "            print(\"Input: \"+' '.join([data_loader.dataset.idx2word[idx] for idx in texts[0].tolist() if idx not in {data_loader.dataset.word2idx[PAD], data_loader.dataset.word2idx[END]}]))\n",
        "            print(\"Prediction:\", pred.item(), '\\tCorrect Output:', labels.item(), '\\n')\n",
        "\n",
        "    full_acc = 100*epoch_acc/total\n",
        "    full_loss = epoch_loss/total\n",
        "    print('[TEST]\\t Loss: {:.4f}\\t Accuracy: {:.2f}%'.format(full_loss, full_acc))\n",
        "    predictions = torch.cat(all_predictions)\n",
        "    return predictions, full_acc, full_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Z718w8e0oNoS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783,
          "referenced_widgets": [
            "100d413f90b64158806e4a5ea315a175",
            "652041bd1fcc4e13a00b74ffc486e82b",
            "268d19fe95d5480b89acfdcc9c9ce5d6",
            "8618359ccc994ac784d8f8f324d8b8a0",
            "3cdbbbb4886c4bf89795c15bef9b846f",
            "cd62cdc539a2444998a1b477809c609b",
            "bc261af2abf644fbae990f54a95e3e3d",
            "920dbee2cae442018fb84ece5a47cca1",
            "16e465de11614f1fa1c4e67f4e064b26",
            "d97be1622051444b97a93e9a69c739c1",
            "fcb8576e52664ee89df3b569360f531e"
          ]
        },
        "outputId": "369538a0-12c9-4358-dcb0-1b24b53b910f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating performance on the test dataset...\n",
            "\n",
            "SOME PREDICTIONS FROM THE MODEL:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "100d413f90b64158806e4a5ea315a175"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: i enjoyed the first reviewer's comment far more than i did the film when i saw it at a <UNK> theatre in the early ' 80's . i was impressed then by the care taken to create costumes <UNK> so closely after the <UNK> drawings . but to me , the cast was largely squandered , their personalities muffled by the masks , while the direction i think of as being unusually static , and the photography murky . the rating <UNK> down at the time was a <UNK> , which means \" not worth sitting through even <UNK> /><br />still , i too would jump at a chance to have a second look .\n",
            "Prediction: 1 \tCorrect Output: 1 \n",
            "\n",
            "Input: for two of the funniest comedians , the movie was awful . fast forwarded it and never got any better ! waste of time and waste of money ! tina fey is such a great writer , i thought that she would be so great in the comedy . the previews were so great , but they only showed the best parts of the movie . my husband even thought that for a chick flick , it sucked . what is up with that . movie was very slow <UNK> boring . i will not recommend it to anyone at this time . i would like my money back for this one ! boo from us here in arizona . thanks but no thanks . who does this kind of stupid stuff to make people think that you are pregnant . i thought that it was going to be so funny , i have had my own children and i have helped others have children . it could have been more along the lines of reality .\n",
            "Prediction: 1 \tCorrect Output: 1 \n",
            "\n",
            "Input: i am a student of film , and have been for several years . and the concept of a cyber , kung-fu , satirical <UNK> had me wondering , \" is this the film that's going to break the <UNK> \" let's face it , america has never been let down by any piece of cinema that features a <UNK> costar . after such great classics as \" monkey trouble \" and \" <UNK> checks <UNK> , i thought that the best ideas were already taken . but then comes \" funky <UNK> . i laughed , i cried , i contemplated <UNK> /><br />now i've read about demon possession in the bible , but that still doesn't explain why someone would create such a product of evil . first off , having at least a shred of intelligence , i realized that a <UNK> was in fact an ape , not a monkey at all . however , i was sure that the filmmakers would clear this problem up further into the film . they didn't . let me sum up this work of art : a company by the name of <UNK> . has decided to train <UNK>\n",
            "Prediction: 1 \tCorrect Output: 1 \n",
            "\n",
            "Input: every once in a long while a movie will come along that will be so awful that i feel compelled to warn people . if i labor all my days and i can save but one soul from watching this movie , how great will be my joy.<br /><br />where to begin my discussion of pain . for starters , there was a musical montage every five minutes . there was no character development . every character was a stereotype . we had swearing guy , fat guy who eats <UNK> , goofy foreign guy , etc . the script felt as if it were being written as the movie was being shot . the production value was so incredibly low that it felt like i was watching a junior high video presentation . have the directors , producers , etc . ever even seen a movie before ? <UNK> is getting worse and worse with every new entry . the concept for this movie sounded so funny . how could you go wrong with gary coleman and a handful of somewhat legitimate actors . but trust me when i say this , things went wrong , very wrong .\n",
            "Prediction: 1 \tCorrect Output: 1 \n",
            "\n",
            "Input: i love the episode where jim becomes the <UNK> . it is great ! when jim tosses that little person through the window , the look on his face is priceless . then when he starts to address the priest in his wife's behalf only to find out that she has become the <UNK> ? great writing and great casting along with great acting makes this a must see . i am attempting to find a certain photo from that episode . i'd like to use it as my <UNK> on a message board because i think the <UNK> is hilarious . does anyone know where i can download a photo of jim as the <UNK> ? can anyone point me in the right direction to find such a photo ?\n",
            "Prediction: 1 \tCorrect Output: 1 \n",
            "\n",
            "Input: first of all this movie is not a comedy ; unless you really force yourself you can hardly laugh . secondly , the movie is slow and boring . the acting is not bad but not special . there is a lucky luke comic about two families ( one with big noses and one with big ears ) fighting each other in a small <UNK> . you will laugh much more if you read this instead of wasting your time with this movie . religions and <UNK> are not the best source to make a good comedy and this movie does nothing more than confirm this rule . there is a similar subject comedy '  ' the home <UNK> '  ; this had some good moments . my final comment is : do not waste your time and money to watch this uninspired and boring film .\n",
            "Prediction: 1 \tCorrect Output: 1 \n",
            "\n",
            "Input: yes , be my love was mario <UNK> <UNK> to fame and still is popular today . his voice was strong and steady , so powerful in fact that mgm decided to use him in the great <UNK> . <UNK> himself thought he was the reincarnation of <UNK> . having read the book by <UNK> who wrote a biography of <UNK> , he explains that the constant <UNK> and vocal lessons became the visionary <UNK> to <UNK> . there is no doubt that <UNK> did a superb job in the story , but the story is not entirely true ; blame it on hollywood ! i used to <UNK> singing his songs years ago , and became pretty good myself until i lost my voice because of <UNK> ten years ago . reaching the high note of be my love is not easy ; but beautiful !\n",
            "Prediction: 1 \tCorrect Output: 1 \n",
            "\n",
            "Input: for a slasher <UNK> movie is actually better than a lot in the <UNK> it is <UNK> nut job goes on killing <UNK> <UNK> yada <UNK> there are some good positives in this <UNK> <UNK> really liked the mask the nut job <UNK> is definitely creepy to say the least and possibly <UNK> i haven't watched every single slasher film ever <UNK> genesis of the bad due is something i haven't seen <UNK> he way he finally meets his end is a novel <UNK> far as i <UNK> also really liked the weapon of choice employed by mr <UNK> most of the <UNK> murders themselves are not as graphic as most in the <UNK> <UNK> small <UNK> movie does not take itself <UNK> is something most slashers suffer <UNK> <UNK> watching the <UNK> was reminded of the early \" friday the 13th <UNK> did take themselves <UNK> are a few concerns about this <UNK> several <UNK> killer suddenly bears a strong resemblance to one of our horror <UNK> <UNK> mean his movements and his reactions upon being <UNK> also the way he <UNK> bigger <UNK> is a scene very close to the <UNK> mr crazy bears a more than striking\n",
            "Prediction: 1 \tCorrect Output: 1 \n",
            "\n",
            "Input: when philo vance ( edmund lowe ) is standing <UNK> on the edge of a balcony high above the city , apparently hypnotized and just about to step to his <UNK> immediately reminded me of a nearly identical scene in another film made nine years later , \" the woman in green \" in which sherlock holmes ( basil <UNK> similarly about to hurl himself into space while being hypnotized . <br /><br <UNK> , both philo vance and sherlock holmes survive these attempts at murder by unscrupulous criminals . exciting cinematic suspense in both these scenes . when will they learn you can't cloud the minds of great fictional detectives  ?\n",
            "Prediction: 1 \tCorrect Output: 1 \n",
            "\n",
            "Input: i just found the imdb and searched this film and i was moved almost to tears by the comments of all the people who saw this film as i did when 6 or so years old in <UNK> . i saw it before the jungle book so i was eagle boy for a few hours and then <UNK> for the next year . i burst into tears at the cinema when the boy turned into the eagle and always wanted to see the film again . when we got home we had a roast chicken dinner and i got the wish bone and guess who i wished to be ? my dad then said ' i bet you wished to be an eagle ' and of course we all know that wishes are broken if someone <UNK> so more tears and a little resentment to this day for not being able to fly <UNK> .\n",
            "Prediction: 1 \tCorrect Output: 1 \n",
            "\n",
            "Input: david lynch's new short is a very \" lynchian \" piece , full of darkness , tension , silences , discreet but very textured background music , and features again two beautiful actresses , a blonde and a brunette , a <UNK> theme in his work.<br /><br />both characters create a very intriguing <UNK> relationship that could be seen as a direct follow up to the same kind of relationship featured in mulholland <UNK> /><br />beautiful . for lynch <UNK> /><br />\n",
            "Prediction: 1 \tCorrect Output: 1 \n",
            "\n",
            "Input: like i said its a hidden surprise . it well written well acted and well cast . i liked everything in this movie . look its hollywood all right but the brighter side . angelina jolie is great in this and i'm totally watching every movie with her in that i can get my hands on . well worth a look .\n",
            "Prediction: 1 \tCorrect Output: 1 \n",
            "\n",
            "[TEST]\t Loss: 0.0000\t Accuracy: 100.00%\n"
          ]
        }
      ],
      "source": [
        "if __name__=='__main__':\n",
        "    evaluate(cnn_model, test_loader, criterion, use_tqdm=True) # Compute test data accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRCFvjwDthiA"
      },
      "source": [
        "# Step 4: Train a Recurrent Neural Network (RNN) [40 points]\n",
        "You will now build a text clasification model that is based on **recurrences**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-t8tlZviV2x"
      },
      "source": [
        "## <font color='red'>TODO:</font> Define the RNN Model [20 points]\n",
        "\n",
        "First, you will define the RNN. As with the CNN, we provide you with the skeleton of the class, and you need to fill in parts of the `__init__(...)` and `forward(...)` methods. Each of these functions is worth 10 points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "2nc_HxbP6klI"
      },
      "outputs": [],
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers, bidirectional, dropout, num_classes, pad_idx):\n",
        "        super(RNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        ##### TODO #####\n",
        "\n",
        "        # Create an embedding layer (https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html)\n",
        "        #   to represent the words in your vocabulary. Make sure to use vocab_size, embed_size, and pad_idx here.\n",
        "\n",
        "        self.emb=nn.Embedding(num_embeddings=vocab_size, embedding_dim=embed_size, padding_idx=pad_idx)\n",
        "\n",
        "        # Create a recurrent network (use nn.GRU, not nn.LSTM) with batch_first = True\n",
        "        # Make sure you use hidden_size, num_layers, dropout, and bidirectional here.\n",
        "\n",
        "        self.rec_net=nn.GRU(input_size =embed_size, hidden_size=hidden_size,num_layers=num_layers,  batch_first = True, dropout=dropout, bidirectional=bidirectional)\n",
        "\n",
        "\n",
        "        # Create a dropout layer (nn.Dropout) using dropout\n",
        "\n",
        "        self.fc1=nn.Dropout(dropout)\n",
        "\n",
        "        # Define a linear layer (nn.Linear) that consists of num_classes units\n",
        "        #   and takes as input the output of the last timestep. In the bidirectional case, you should concatenate\n",
        "        #   the output of the last timestep of the forward direction with the output of the last timestep of the backward direction).\n",
        "        if(bidirectional==True):\n",
        "          n=2\n",
        "        else:\n",
        "          n=1\n",
        "\n",
        "        self.fc2=nn.Linear(self.hidden_size*n, num_classes)\n",
        "\n",
        "\n",
        "    def forward(self, texts):\n",
        "        \"\"\"\n",
        "        texts: LongTensor [batch_size, MAX_LEN]\n",
        "\n",
        "        Returns output: Tensor [batch_size, num_classes]\n",
        "        \"\"\"\n",
        "        ##### TODO #####\n",
        "\n",
        "        # Pass texts through your embedding layer to convert from word ids to word embeddings\n",
        "        #   Resulting: shape: [batch_size, max_len, embed_size]\n",
        "\n",
        "        # Pass the result through your recurrent network\n",
        "        #   See PyTorch documentation for resulting shape for nn.GRU\n",
        "\n",
        "        # Concatenate the outputs of the last timestep for each direction (see torch.cat(...))\n",
        "        #   This depends on whether or not your model is bidirectional.\n",
        "        #   Resulting shape: [batch_size, num_dirs*hidden_size]\n",
        "\n",
        "        # Apply dropout\n",
        "\n",
        "        # Pass your output through the linear layer and return its output\n",
        "        #   Resulting shape: [batch_size, num_classes]\n",
        "\n",
        "        ##### NOTE: Do not apply a sigmoid or softmax to the final output - done in training method!\n",
        "\n",
        "        out=self.emb(texts)\n",
        "        out, hidden = self.rec_net(out)\n",
        "        #hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n",
        "        out=self.fc1(out[:, -1, :])\n",
        "        out=self.fc2(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDLTiJMyoLxJ"
      },
      "source": [
        "##Sanity Check: RNN Model\n",
        "\n",
        "The code below runs a sanity check for your `RNN` class. The tests are similar to the hidden ones in Gradescope. However, note that passing the sanity check does <b>not</b> guarantee that you will pass the autograder; it is intended to help you debug."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Duq7X2ClwXga",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2554010c-d147-4652-a2cc-e58738579536"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- TEST: Number of Model Parameters (tests __init__(...)) ---\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 44546\tYour Num. Params: 44546\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 44676\tYour Num. Params: 44676\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 27202\tYour Num. Params: 27202\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 27268\tYour Num. Params: 27268\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 82178\tYour Num. Params: 82178\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 82308\tYour Num. Params: 82308\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 39874\tYour Num. Params: 39874\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 39940\tYour Num. Params: 39940\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 1620610\tYour Num. Params: 1620610\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 1621636\tYour Num. Params: 1621636\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 621698\tYour Num. Params: 621698\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 622212\tYour Num. Params: 622212\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 3986050\tYour Num. Params: 3986050\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 3987076\tYour Num. Params: 3987076\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 1411202\tYour Num. Params: 1411202\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 1411716\tYour Num. Params: 1411716\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 101762\tYour Num. Params: 101762\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 101892\tYour Num. Params: 101892\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 79810\tYour Num. Params: 79810\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 79876\tYour Num. Params: 79876\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 139394\tYour Num. Params: 139394\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 139524\tYour Num. Params: 139524\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 92482\tYour Num. Params: 92482\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 92548\tYour Num. Params: 92548\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 1742338\tYour Num. Params: 1742338\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 1743364\tYour Num. Params: 1743364\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 706562\tYour Num. Params: 706562\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 707076\tYour Num. Params: 707076\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 4107778\tYour Num. Params: 4107778\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 4108804\tYour Num. Params: 4108804\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 1496066\tYour Num. Params: 1496066\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 1496580\tYour Num. Params: 1496580\n",
            "\n",
            "--- TEST: Output shape of forward(...) ---\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 2])\tYour Output Shape: torch.Size([2, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 4])\tYour Output Shape: torch.Size([1, 4])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 4])\tYour Output Shape: torch.Size([2, 4])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 2])\tYour Output Shape: torch.Size([2, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 4])\tYour Output Shape: torch.Size([1, 4])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 4])\tYour Output Shape: torch.Size([2, 4])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 2])\tYour Output Shape: torch.Size([2, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 4])\tYour Output Shape: torch.Size([1, 4])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 4])\tYour Output Shape: torch.Size([2, 4])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 2])\tYour Output Shape: torch.Size([2, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 4])\tYour Output Shape: torch.Size([1, 4])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 4])\tYour Output Shape: torch.Size([2, 4])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 2])\tYour Output Shape: torch.Size([2, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 4])\tYour Output Shape: torch.Size([1, 4])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 4])\tYour Output Shape: torch.Size([2, 4])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 2])\tYour Output Shape: torch.Size([2, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 4])\tYour Output Shape: torch.Size([1, 4])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 4])\tYour Output Shape: torch.Size([2, 4])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 2])\tYour Output Shape: torch.Size([2, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 4])\tYour Output Shape: torch.Size([1, 4])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 4])\tYour Output Shape: torch.Size([2, 4])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 2])\tYour Output Shape: torch.Size([2, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 4])\tYour Output Shape: torch.Size([1, 4])\n",
            "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 4])\tYour Output Shape: torch.Size([2, 4])\n"
          ]
        }
      ],
      "source": [
        "### DO NOT EDIT ###\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Test init\n",
        "    inputs = [{'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}]\n",
        "    expected_outputs = [44546, 44676, 27202, 27268, 82178, 82308, 39874, 39940, 1620610, 1621636, 621698, 622212, 3986050, 3987076, 1411202, 1411716, 101762, 101892, 79810, 79876, 139394, 139524, 92482, 92548, 1742338, 1743364, 706562, 707076, 4107778, 4108804, 1496066, 1496580]\n",
        "\n",
        "    sanityCheckModel(inputs, RNN, expected_outputs, \"init\", None)\n",
        "    print()\n",
        "\n",
        "    # Test forward\n",
        "    inputs = [{'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 2}]\n",
        "    expected_outputs = [torch.Size([1, 2]), torch.Size([2, 2]), torch.Size([1, 4]), torch.Size([2, 4]), torch.Size([1, 2]), torch.Size([2, 2]), torch.Size([1, 4]), torch.Size([2, 4]), torch.Size([1, 2]), torch.Size([2, 2]), torch.Size([1, 4]), torch.Size([2, 4]), torch.Size([1, 2]), torch.Size([2, 2]), torch.Size([1, 4]), torch.Size([2, 4]), torch.Size([1, 2]), torch.Size([2, 2]), torch.Size([1, 4]), torch.Size([2, 4]), torch.Size([1, 2]), torch.Size([2, 2]), torch.Size([1, 4]), torch.Size([2, 4]), torch.Size([1, 2]), torch.Size([2, 2]), torch.Size([1, 4]), torch.Size([2, 4]), torch.Size([1, 2]), torch.Size([2, 2]), torch.Size([1, 4]), torch.Size([2, 4])]\n",
        "    sanity_dataset = TextDataset(train_data, 'train', 5, 150)\n",
        "    sanity_loader = torch.utils.data.DataLoader(sanity_dataset, batch_size=50, shuffle=True, num_workers=2, drop_last=True)\n",
        "\n",
        "    sanityCheckModel(inputs, RNN, expected_outputs, \"forward\", sanity_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baD8lYAytdTV"
      },
      "source": [
        "## Train RNN Model\n",
        "First, we initialize the train and test dataloaders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "WCzNm8LDM5aT"
      },
      "outputs": [],
      "source": [
        "if __name__=='__main__':\n",
        "    THRESHOLD = 5 # Don't change this\n",
        "    MAX_LEN = 200 # Don't change this\n",
        "    BATCH_SIZE = 20 # Feel free to try other batch sizes\n",
        "\n",
        "    train_dataset = TextDataset(train_data, 'train', THRESHOLD, MAX_LEN)\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, drop_last=True)\n",
        "\n",
        "    test_dataset = TextDataset(test_data, 'test', THRESHOLD, MAX_LEN, train_dataset.idx2word, train_dataset.word2idx)\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=1, drop_last=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lp5pAz8emxi2"
      },
      "source": [
        "Now you can instantiate your model. We provide you with some recommended hyperparameters; you should be able to get the desired accuracy with these, but feel free to play around with them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "CA-UairGErap",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddfbedf5-5811-4235-d5b3-b0c864f7eab8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 4,300,546 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "if __name__=='__main__':\n",
        "    rnn_model = RNN(vocab_size = train_dataset.vocab_size, # Don't change this\n",
        "                embed_size = 128,\n",
        "                hidden_size = 128,\n",
        "                num_layers = 2,\n",
        "                bidirectional = True,\n",
        "                dropout = 0.5,\n",
        "                num_classes = 2, # Don't change this\n",
        "                pad_idx = train_dataset.word2idx[PAD]) # Don't change this\n",
        "\n",
        "    # Put your model on device\n",
        "    rnn_model = rnn_model.to(DEVICE)\n",
        "\n",
        "    print('The model has {:,d} trainable parameters'.format(count_parameters(rnn_model)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqngFY4MoLec"
      },
      "source": [
        "Here, we create the criterion and optimizer; as with the CNN, we use cross-entropy loss and Adam optimization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "em6Rs58OlJ3Z"
      },
      "outputs": [],
      "source": [
        "if __name__=='__main__':\n",
        "    LEARNING_RATE = 1e-5 # Feel free to try other learning rates\n",
        "\n",
        "    # Define your loss function\n",
        "    criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
        "\n",
        "    # Define your optimizer\n",
        "    optimizer = optim.Adam(rnn_model.parameters(), lr=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEPsi3choUm5"
      },
      "source": [
        "Finally, we can train the model. We use the same `train_model(...)` function that we defined for the CNN. If the model is implemented correctly and you're using the GPU, this cell should take around <b>2 minutes</b> (or less). Feel free to change the number of epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "NR8Wckf0l2G7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281,
          "referenced_widgets": [
            "99da153b30eb462381f00b070400268e",
            "ac2fe96a2c0646bc90ae27bd34169b3c",
            "e2c2017987c948449464e71f2130e982",
            "f8aa8debd4754d839ed1910e4b2f17c2",
            "3aae56b4b4564d72be48fbac223ac430",
            "5b511dc0b3474dac88b2275cae14ba15",
            "80e33c8c61e64d628781c807eadec88a",
            "11328be6a9f94286b82ad55a4a57c5d1",
            "076651e11c2640f7ae32d7b8d99f3cf7",
            "92d8f686606540f58278695a0c5e4181",
            "ae4f7b9417ce4fef983aef9df7683fec"
          ]
        },
        "outputId": "e6bf9223-aab4-4e35-8ce4-785e4d611623"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "99da153b30eb462381f00b070400268e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]\t Epoch:  1\t Loss: 0.2847\t Train Accuracy: 98.74%\n",
            "[TRAIN]\t Epoch:  2\t Loss: 0.0066\t Train Accuracy: 100.00%\n",
            "[TRAIN]\t Epoch:  3\t Loss: 0.0020\t Train Accuracy: 100.00%\n",
            "[TRAIN]\t Epoch:  4\t Loss: 0.0008\t Train Accuracy: 100.00%\n",
            "[TRAIN]\t Epoch:  5\t Loss: 0.0003\t Train Accuracy: 100.00%\n",
            "[TRAIN]\t Epoch:  6\t Loss: 0.0002\t Train Accuracy: 100.00%\n",
            "[TRAIN]\t Epoch:  7\t Loss: 0.0001\t Train Accuracy: 100.00%\n",
            "[TRAIN]\t Epoch:  8\t Loss: 0.0001\t Train Accuracy: 100.00%\n",
            "[TRAIN]\t Epoch:  9\t Loss: 0.0000\t Train Accuracy: 100.00%\n",
            "[TRAIN]\t Epoch: 10\t Loss: 0.0000\t Train Accuracy: 100.00%\n",
            "Model Trained!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "if __name__=='__main__':\n",
        "    N_EPOCHS = 10 # Feel free to change this\n",
        "\n",
        "    # train model for N_EPOCHS epochs\n",
        "    train_model(rnn_model, N_EPOCHS, train_loader, optimizer, criterion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-SRIFfooYk6"
      },
      "source": [
        "## Evaluate RNN Model [20 points]\n",
        "\n",
        "Now we can evaluate the RNN.\n",
        "\n",
        "To pass the autograder for the RNN, you will need to achieve **82% accuracy** on the hidden test set on Gradescope. Note that the Gradescope test set is very similar, and the accuracies between the two datasets should be comparable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "HYon4AbHl5_M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408,
          "referenced_widgets": [
            "e136e71cc2d8481b9d7934208011bd4d",
            "aadd9bbc1d164f7d8f12d7ae8ad9166c",
            "976d47f2db5b4a4eb2920e2a3b722b83",
            "63462273cf8041919595433b563df8fa",
            "45f25961af884611abab81707d0cee27",
            "b40e737906d945d7b773b7c102b48417",
            "d6c7933472494071aad827477422fb28",
            "6aeb3658ce76466984dff234e13e5a10",
            "4cd7590a75d249cd8d93cc303ec46a5d",
            "3ec8da396dec4fe1bb092e8f5bd4aa99",
            "12d83b130aa247088f42e2af829b1068"
          ]
        },
        "outputId": "1775dc1c-feab-4ed1-f579-181651e3a074"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating performance on the test dataset...\n",
            "\n",
            "SOME PREDICTIONS FROM THE MODEL:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e136e71cc2d8481b9d7934208011bd4d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: the characters are unlikeable and the script is awful . it's a waste of the talents of <UNK> and auteuil .\n",
            "Prediction: 1 \tCorrect Output: 1 \n",
            "\n",
            "Input: there are a lot of pretentious people out there who will pretend that this is endowed with some kind of beautiful meaning , and that ignorant fools like me don't ' get ' it . obviously this means that we should stick to hollywood <UNK> /><br />it has every , <UNK> , artistic cliché in the book - i guess it is good that the director is one of the chosen few . almost a self parody drowning in its own <UNK> /><br />the director of the ( almost equally embarrassing ) movie ' <UNK> ' returns with another piece <UNK> in artistic nonsense ; it is difficult to understand and apparently is a study of alienation . the best way to describe this film is alienating for its viewers .\n",
            "Prediction: 1 \tCorrect Output: 1 \n",
            "\n",
            "Input: i am definitely a burt reynolds fan , but sorry , this one really stinks . most of the dialogue is laughable and the only interesting plot twist is in the last five minutes of the movie . i can't believe he even made this one . is he actually that hard up for money ?\n",
            "Prediction: 1 \tCorrect Output: 1 \n",
            "\n",
            "Input: <UNK> must admit that it isn't a good movie . <UNK> would never watch this movie if pacino wasn't in it.<br /><br />the movie is about a <UNK> strange 24 <UNK> he is <UNK> and sometimes <UNK> don't like the character at <UNK> really <UNK> 20 minutes you may fall <UNK> i don't understand why pacino wanted to be a part of this horrible <UNK> because of money or what?<br /><br />since i'm an avid pacino <UNK> bought this 2002 movie people i <UNK> you haven't bought it <UNK> even think about <UNK> just a waste of time .\n",
            "Prediction: 1 \tCorrect Output: 1 \n",
            "\n",
            "Input: this was a must see documentary for me when i missed the opportunity in 2004 , so i was definitely going to watch the repeat . i really <UNK> with the main character of the film , because , this is true , i have a milder condition of the skin problem he had , <UNK> <UNK> <UNK> ( <UNK> . this is a sad , sometimes amusing and very emotional documentary about a boy with a terrible skin disorder . <UNK> kennedy speaks like a kid ( because of wasting vocal muscle ) and never went through puberty , but he is 36 years old . most <UNK> moments are seeing his terrible condition , and <UNK> off his <UNK> . <UNK> had quite a naughty sense of humour , he even narrated from beyond the grave when showing his body in a coffin . he tells his story with the help of his mother , edna kennedy , his older brother and celebrity model , and <UNK> supporter , nell mcandrew . it won the <UNK> for best editing and best new director ( <UNK> , and it was nominated for best sound ( factual ) and the\n",
            "Prediction: 1 \tCorrect Output: 1 \n",
            "\n",
            "[TEST]\t Loss: 0.0000\t Accuracy: 100.00%\n"
          ]
        }
      ],
      "source": [
        "if __name__=='__main__':\n",
        "    evaluate(rnn_model, test_loader, criterion, use_tqdm=True) # Compute test data accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WQAV6O2xHvS"
      },
      "source": [
        "# What to Submit\n",
        "\n",
        "To submit the assignment, download this notebook as a <TT>.py</TT> file. You can do this by going to <TT>File > Download > Download .py</TT>. Then (optionally) rename it to `hwk2.py`.\n",
        "\n",
        "You will also need to save the `cnn_model` and `rnn_model`. You can run the cell below to do this. After you save the files to your Google Drive, you need to manually download the files to your computer, and then submit them to the autograder.\n",
        "\n",
        "You will submit the following files to the autograder:\n",
        "1.   `hwk2.py`, the download of this notebook as a `.py` file (**not** a `.ipynb` file)\n",
        "1.   `cnn.pt`, the saved version of your `cnn_model`\n",
        "1.   `rnn.pt`, the saved version of your `rnn_model`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "abbbMNi8X_ai",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2711e495-2d3e-4be3-aec4-2eaa52ecf06f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "\n",
            "Saving CNN model....\n",
            "Saving RNN model....\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "### DO NOT EDIT ###\n",
        "\n",
        "if __name__=='__main__':\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    print()\n",
        "\n",
        "    try:\n",
        "        cnn_model is None\n",
        "        cnn_exists = True\n",
        "    except:\n",
        "        cnn_exists = False\n",
        "\n",
        "    try:\n",
        "        rnn_model is None\n",
        "        rnn_exists = True\n",
        "    except:\n",
        "        rnn_exists = False\n",
        "\n",
        "    if cnn_exists:\n",
        "        print(\"Saving CNN model....\")\n",
        "        torch.save(cnn_model, \"drive/My Drive/cnn.pt\")\n",
        "    if rnn_exists:\n",
        "        print(\"Saving RNN model....\")\n",
        "        torch.save(rnn_model, \"drive/My Drive/rnn.pt\")\n",
        "    print(\"Done!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b45670bfd5274a0287a2b67d963e80f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_13773b59fd91438b90b345809b87a65d",
              "IPY_MODEL_54f8f34e92d94cdca30496ce06249e39",
              "IPY_MODEL_fc49e9d5724e44b5a5bf6b4d18017b68"
            ],
            "layout": "IPY_MODEL_eff426beaa51478ab57e32da45a975bf"
          }
        },
        "13773b59fd91438b90b345809b87a65d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8281df0737e4d188c988552e8d7c077",
            "placeholder": "​",
            "style": "IPY_MODEL_10ec98051c3448ea845babbd907b8f5e",
            "value": "100%"
          }
        },
        "54f8f34e92d94cdca30496ce06249e39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d814f779d2bb454f87f5ad95f5eb3d1e",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8c80eb1efa1e448eab81304a5d3e5955",
            "value": 10
          }
        },
        "fc49e9d5724e44b5a5bf6b4d18017b68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7721712e2c04b6fb31a8331d0e4ef45",
            "placeholder": "​",
            "style": "IPY_MODEL_b25960dc9f6a4cc28fe19997f7a2e2ec",
            "value": " 10/10 [06:12&lt;00:00, 36.48s/it]"
          }
        },
        "eff426beaa51478ab57e32da45a975bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8281df0737e4d188c988552e8d7c077": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10ec98051c3448ea845babbd907b8f5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d814f779d2bb454f87f5ad95f5eb3d1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c80eb1efa1e448eab81304a5d3e5955": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f7721712e2c04b6fb31a8331d0e4ef45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b25960dc9f6a4cc28fe19997f7a2e2ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "100d413f90b64158806e4a5ea315a175": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_652041bd1fcc4e13a00b74ffc486e82b",
              "IPY_MODEL_268d19fe95d5480b89acfdcc9c9ce5d6",
              "IPY_MODEL_8618359ccc994ac784d8f8f324d8b8a0"
            ],
            "layout": "IPY_MODEL_3cdbbbb4886c4bf89795c15bef9b846f"
          }
        },
        "652041bd1fcc4e13a00b74ffc486e82b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd62cdc539a2444998a1b477809c609b",
            "placeholder": "​",
            "style": "IPY_MODEL_bc261af2abf644fbae990f54a95e3e3d",
            "value": "100%"
          }
        },
        "268d19fe95d5480b89acfdcc9c9ce5d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_920dbee2cae442018fb84ece5a47cca1",
            "max": 5000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_16e465de11614f1fa1c4e67f4e064b26",
            "value": 5000
          }
        },
        "8618359ccc994ac784d8f8f324d8b8a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d97be1622051444b97a93e9a69c739c1",
            "placeholder": "​",
            "style": "IPY_MODEL_fcb8576e52664ee89df3b569360f531e",
            "value": " 5000/5000 [00:15&lt;00:00, 340.80it/s]"
          }
        },
        "3cdbbbb4886c4bf89795c15bef9b846f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd62cdc539a2444998a1b477809c609b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc261af2abf644fbae990f54a95e3e3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "920dbee2cae442018fb84ece5a47cca1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16e465de11614f1fa1c4e67f4e064b26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d97be1622051444b97a93e9a69c739c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcb8576e52664ee89df3b569360f531e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99da153b30eb462381f00b070400268e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ac2fe96a2c0646bc90ae27bd34169b3c",
              "IPY_MODEL_e2c2017987c948449464e71f2130e982",
              "IPY_MODEL_f8aa8debd4754d839ed1910e4b2f17c2"
            ],
            "layout": "IPY_MODEL_3aae56b4b4564d72be48fbac223ac430"
          }
        },
        "ac2fe96a2c0646bc90ae27bd34169b3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b511dc0b3474dac88b2275cae14ba15",
            "placeholder": "​",
            "style": "IPY_MODEL_80e33c8c61e64d628781c807eadec88a",
            "value": "100%"
          }
        },
        "e2c2017987c948449464e71f2130e982": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11328be6a9f94286b82ad55a4a57c5d1",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_076651e11c2640f7ae32d7b8d99f3cf7",
            "value": 10
          }
        },
        "f8aa8debd4754d839ed1910e4b2f17c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92d8f686606540f58278695a0c5e4181",
            "placeholder": "​",
            "style": "IPY_MODEL_ae4f7b9417ce4fef983aef9df7683fec",
            "value": " 10/10 [01:43&lt;00:00, 10.16s/it]"
          }
        },
        "3aae56b4b4564d72be48fbac223ac430": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b511dc0b3474dac88b2275cae14ba15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80e33c8c61e64d628781c807eadec88a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11328be6a9f94286b82ad55a4a57c5d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "076651e11c2640f7ae32d7b8d99f3cf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "92d8f686606540f58278695a0c5e4181": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae4f7b9417ce4fef983aef9df7683fec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e136e71cc2d8481b9d7934208011bd4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aadd9bbc1d164f7d8f12d7ae8ad9166c",
              "IPY_MODEL_976d47f2db5b4a4eb2920e2a3b722b83",
              "IPY_MODEL_63462273cf8041919595433b563df8fa"
            ],
            "layout": "IPY_MODEL_45f25961af884611abab81707d0cee27"
          }
        },
        "aadd9bbc1d164f7d8f12d7ae8ad9166c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b40e737906d945d7b773b7c102b48417",
            "placeholder": "​",
            "style": "IPY_MODEL_d6c7933472494071aad827477422fb28",
            "value": "100%"
          }
        },
        "976d47f2db5b4a4eb2920e2a3b722b83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6aeb3658ce76466984dff234e13e5a10",
            "max": 5000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4cd7590a75d249cd8d93cc303ec46a5d",
            "value": 5000
          }
        },
        "63462273cf8041919595433b563df8fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ec8da396dec4fe1bb092e8f5bd4aa99",
            "placeholder": "​",
            "style": "IPY_MODEL_12d83b130aa247088f42e2af829b1068",
            "value": " 5000/5000 [00:21&lt;00:00, 260.08it/s]"
          }
        },
        "45f25961af884611abab81707d0cee27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b40e737906d945d7b773b7c102b48417": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6c7933472494071aad827477422fb28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6aeb3658ce76466984dff234e13e5a10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cd7590a75d249cd8d93cc303ec46a5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ec8da396dec4fe1bb092e8f5bd4aa99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12d83b130aa247088f42e2af829b1068": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}